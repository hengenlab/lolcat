{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data.sampler import WeightedRandomSampler,SubsetRandomSampler\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix,f1_score,accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from collections import Counter\n",
    "#from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../')\n",
    "\n",
    "from src import Dataset\n",
    "from src.network import MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] =\"7\" #specify gpu to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data.\n",
      "(neuropixels) trial data not yet implemented. Using V1 trial data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n# cell classes identified by Louis as not being too quiet\\nkeepers = ['e5Rbp4', 'e23Cux2', 'i6Pvalb', 'e4Scnn1a', 'i23Pvalb', 'i23Htr3a',\\n 'e4Rorb', 'e4other', 'i5Pvalb', 'i4Pvalb', 'i23Sst', 'i4Sst', 'e4Nr5a1',\\n 'i1Htr3a', 'e5noRbp4', 'i6Sst', 'e6Ntsr1']\\ndataset.drop_other_classes(classes_to_keep=keepers)\\n\""
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_root = '../data/'\n",
    "dataset = Dataset(data_root, data_source='neuropixels', labels_col='subclass', force_process=True) #specify data location\n",
    "\n",
    "\n",
    "#dataset.drop_dead_cells(cutoff=30)\n",
    "\n",
    "#Removing any class with less than 10 members\n",
    "cell_type_idx_counts_dict = dict(Counter(dataset.cell_type_ids))\n",
    "cell_type_counts = [cell_type_idx_counts_dict[idx] for idx,ctl in enumerate(dataset.cell_type_labels)]\n",
    "#cell_type_counts_dict = dict(zip(dataset.cell_type_labels,cell_type_counts))\n",
    "#keepers = [cell_type for cell_type in dataset.cell_type_labels if cell_type_counts_dict[cell_type] >= 10]\n",
    "keepers = ['Sst','Vip','Pvalb']\n",
    "dataset.drop_other_classes(classes_to_keep=keepers)\n",
    "\n",
    "#each sample must have atleast 30 spikes\n",
    "dataset.drop_dead_cells(cutoff=30)\n",
    "\n",
    "'''\n",
    "# cell classes identified by Louis as not being too quiet\n",
    "keepers = ['e5Rbp4', 'e23Cux2', 'i6Pvalb', 'e4Scnn1a', 'i23Pvalb', 'i23Htr3a',\n",
    " 'e4Rorb', 'e4other', 'i5Pvalb', 'i4Pvalb', 'i23Sst', 'i4Sst', 'e4Nr5a1',\n",
    " 'i1Htr3a', 'e5noRbp4', 'i6Sst', 'e6Ntsr1']\n",
    "dataset.drop_other_classes(classes_to_keep=keepers)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sst', 'Vip', 'Pvalb']\n"
     ]
    }
   ],
   "source": [
    "print(keepers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sst', 'Pvalb', 'Vip']\n"
     ]
    }
   ],
   "source": [
    "print(dataset.cell_type_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({2.0: 4902, 0.0: 60, 1.0: 40})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(dataset.cell_type_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slotnames__', '__str__', '__subclasshook__', '__weakref__', '_load_cell_metadata', '_load_spike_data', '_load_trial_data', '_look_for_processed_file', '_select_data', '_trial_split', 'aggregate_cell_classes', 'cell_ids', 'cell_type_ids', 'cell_type_labels', 'data_source', 'drop_dead_cells', 'drop_other_classes', 'get_set', 'labels_col', 'load', 'num_cell_types', 'num_trials', 'parse_mode', 'processed_dir', 'processed_file', 'raw_dir', 'root_dir', 'save', 'spike_times', 'split_cell_train_val_test', 'split_trial_train_val_test', 'trial_length', 'trial_table']\n"
     ]
    }
   ],
   "source": [
    "print(dir(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "random_seed = 1\n",
    "test_size, val_size = 0.2, 0.2\n",
    "\n",
    "dataset.split_cell_train_val_test(test_size=test_size, val_size=val_size, seed=random_seed)\n",
    "X_train, y_train = dataset.get_set('train')\n",
    "X_val, y_val = dataset.get_set('val')\n",
    "X_test, y_test = dataset.get_set('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute ISI distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hist(X, bins, a_min=-2.5, a_max=0.5):\n",
    "    X_isi = np.zeros((X.shape[0], bins))\n",
    "    bins = np.linspace(a_min, a_max, bins+1)\n",
    "    for i, x in enumerate(X):\n",
    "        # compute isi\n",
    "        x = np.diff(x)\n",
    "        # compute histogram\n",
    "        x = np.log10(x)\n",
    "        # x = np.clip(x, a_min=a_min, a_max=a_max)\n",
    "        X_isi[i] = np.histogram(x, bins)[0].astype(int)\n",
    "    return X_isi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bins = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = compute_hist(X_train, bins=num_bins)\n",
    "X_val = compute_hist(X_val, bins=num_bins)\n",
    "X_test = compute_hist(X_test, bins=num_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 100, 128)\n"
     ]
    }
   ],
   "source": [
    "# reshape to (num_cells, num_trials, num_isi_bins)\n",
    "X_train = X_train.reshape(100, -1, num_bins).transpose(1,0,2)\n",
    "X_val = X_val.reshape(100, -1, num_bins).transpose(1,0,2)\n",
    "X_test = X_test.reshape(100, -1, num_bins).transpose(1,0,2)\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(100, -1).T[:, 0]\n",
    "y_val = y_val.reshape(100, -1).T[:, 0]\n",
    "y_test = y_test.reshape(100, -1).T[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "X_train, y_train = torch.FloatTensor(X_train).to(device), torch.LongTensor(y_train).to(device)\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "\n",
    "X_test, y_test = torch.FloatTensor(X_test).to(device), torch.LongTensor(y_test).to(device)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "X_val, y_val = torch.FloatTensor(X_val).to(device), torch.LongTensor(y_val).to(device)\n",
    "val_dataset = TensorDataset(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, class_sample_count = torch.unique(y_train, return_counts=True)\n",
    "increase_factor = torch.floor(torch.pow(1.5, torch.floor(9 - torch.log(class_sample_count.float()))))\n",
    "indices = []\n",
    "for cell_type, factor in enumerate(increase_factor.cpu()):\n",
    "    if cell_type == 16:\n",
    "        continue\n",
    "    cell_indices = torch.where(y_train==cell_type)[0]\n",
    "    for _ in range(int(factor)):\n",
    "        indices.append(cell_indices)\n",
    "        \n",
    "indices = torch.cat(indices)\n",
    "sampler = SubsetRandomSampler(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=128, sampler=sampler, drop_last=True)\n",
    "train_eval_loader = DataLoader(train_dataset, batch_size=512, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=512, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class EncoderAggr(nn.Module):\n",
    "    def __init__(self, encoder, classifier, dropout_p=0.):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.classifier = classifier\n",
    "        \n",
    "        self.dropout_p = dropout_p\n",
    "        \n",
    "    def dropout(self, x):\n",
    "        if self.training and not self.dropout_p == 0:\n",
    "            dropout_mask = torch.empty((x.size(0), x.size(1), 1), dtype=torch.float32, device=x.device).uniform_(0, 1) > self.dropout_p\n",
    "            dropout_ratio = torch.true_divide(dropout_mask.sum(dim=1),dropout_mask.size(1))\n",
    "\n",
    "            x = x * dropout_mask / dropout_ratio.view(x.size(0), 1, -1)\n",
    "        return x\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x = x.view(-1, num_bins)\n",
    "        emb = self.encoder(x)\n",
    "        \n",
    "        # aggregate feats\n",
    "        emb = emb.view(batch_size, 100, -1)\n",
    "        \n",
    "        # feature dropout\n",
    "        emb = self.dropout(emb)\n",
    "        \n",
    "        # compute global embedding\n",
    "        global_emb = torch.mean(emb, dim=1)\n",
    "        \n",
    "        out = self.classifier(global_emb)\n",
    "        \n",
    "        return nn.functional.log_softmax(out, dim=1)\n",
    "\n",
    "class MLPAggr(nn.Module):\n",
    "    def __init__(self, feat_dropout_p=0.2, net_dropout_p=0.2):\n",
    "        super().__init__()\n",
    "        encoder = nn.Sequential(nn.Linear(128, 128), nn.ReLU(), nn.Dropout(net_dropout_p), \n",
    "                                #nn.Linear(128, 128), nn.ReLU(), nn.Dropout(net_dropout_p), \n",
    "                                #nn.Linear(128, 128), nn.ReLU(), nn.Dropout(net_dropout_p),\n",
    "                                nn.Linear(128, 64), nn.ReLU(), nn.Dropout(net_dropout_p), \n",
    "                                nn.Linear(64, 64), nn.ReLU(), nn.Dropout(net_dropout_p), \n",
    "                                nn.Linear(64, 32))\n",
    "        classifier = nn.Sequential(nn.Linear(32, 32), nn.ReLU(), nn.Linear(32, 17))\n",
    "        self.model = EncoderAggr(encoder, classifier, feat_dropout_p)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "class topk_NLLLoss(nn.Module):\n",
    "    def __init__(self, top_k=0.7):\n",
    "        super().__init__()\n",
    "        self.loss = nn.NLLLoss(reduction='none')\n",
    "        self.top_k = top_k\n",
    "    \n",
    "    def forward(self, input, target):\n",
    "        loss = self.loss(input, target)\n",
    "\n",
    "        if self.top_k == 1:\n",
    "            return torch.mean(loss)\n",
    "        else:\n",
    "            valid_loss, idxs = torch.topk(loss, int(self.top_k * loss.size()[0]))    \n",
    "            return torch.mean(valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN THE MODEL\n",
    "model = MLPAggr(feat_dropout_p=0.3, net_dropout_p=0.2).to(device)\n",
    "\n",
    "lr = 1e-6\n",
    "weight_decay = 1e-6\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "criterion = topk_NLLLoss(0.7)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5000], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32625"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer):\n",
    "    model.train()\n",
    "    avg_loss = 0.\n",
    "    step = 0\n",
    "    for data, target in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_loss += loss.item()\n",
    "        step += 1\n",
    "        \n",
    "    print('loss %.3f (%d)' %(avg_loss/step, step))\n",
    "\n",
    "\n",
    "def test(model, device, loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    preds = []\n",
    "    corrects = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            pred_ = np.ndarray.flatten(pred.cpu().numpy())\n",
    "            targ_ = target.cpu().numpy()\n",
    "            preds.append(pred_)\n",
    "            corrects.append(targ_)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            total += len(target)\n",
    "    corrects = np.hstack(corrects)\n",
    "    preds = np.hstack(preds)\n",
    "    \n",
    "    bad_class = corrects != 16\n",
    "    corrects = corrects[bad_class]\n",
    "    preds = preds[bad_class]\n",
    "    \n",
    "    acc = accuracy_score(corrects, preds)\n",
    "    f1score = f1_score(corrects, preds, average='macro')\n",
    "    cm = confusion_matrix(corrects, preds, normalize='true')\n",
    "    return acc, f1score, cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Hyperparameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 2.802 (26)\n",
      "[[1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.99898063 0.         0.         0.00101937]\n",
      " [0.         0.         0.         0.        ]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.802 (26)\n",
      "[[1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.99898063 0.         0.         0.00101937]\n",
      " [0.         0.         0.         0.        ]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.801 (26)\n",
      "[[1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.99898063 0.         0.         0.00101937]\n",
      " [0.         0.         0.         0.        ]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.801 (26)\n",
      "[[1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.99898063 0.         0.         0.00101937]\n",
      " [0.         0.         0.         0.        ]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.800 (26)\n",
      "[[1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.99898063 0.         0.         0.00101937]\n",
      " [0.         0.         0.         0.        ]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.800 (26)\n",
      "[[1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.99898063 0.         0.         0.00101937]\n",
      " [0.         0.         0.         0.        ]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.800 (26)\n",
      "[[1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.99898063 0.         0.         0.00101937]\n",
      " [0.         0.         0.         0.        ]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.799 (26)\n",
      "[[1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.99898063 0.         0.         0.00101937]\n",
      " [0.         0.         0.         0.        ]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.799 (26)\n",
      "[[1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.99898063 0.         0.         0.00101937]\n",
      " [0.         0.         0.         0.        ]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.799 (26)\n",
      "[[1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.99898063 0.         0.         0.00101937]\n",
      " [0.         0.         0.         0.        ]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.798 (26)\n",
      "[[1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.99898063 0.         0.         0.00101937]\n",
      " [0.         0.         0.         0.        ]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.797 (26)\n",
      "[[1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.99898063 0.         0.         0.00101937]\n",
      " [0.         0.         0.         0.        ]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.798 (26)\n",
      "[[1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.99898063 0.         0.         0.00101937]\n",
      " [0.         0.         0.         0.        ]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.797 (26)\n",
      "[[1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.99898063 0.         0.         0.00101937]\n",
      " [0.         0.         0.         0.        ]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.796 (26)\n",
      "[[1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.99898063 0.         0.         0.00101937]\n",
      " [0.         0.         0.         0.        ]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.796 (26)\n",
      "[[1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.99898063 0.         0.         0.00101937]\n",
      " [0.         0.         0.         0.        ]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.796 (26)\n",
      "[[1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.99898063 0.         0.         0.00101937]\n",
      " [0.         0.         0.         0.        ]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.795 (26)\n",
      "[[1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.99898063 0.         0.         0.00101937]\n",
      " [0.         0.         0.         0.        ]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.795 (26)\n",
      "[[1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.99898063 0.         0.         0.00101937]\n",
      " [0.         0.         0.         0.        ]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.795 (26)\n",
      "[[1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.99898063 0.         0.         0.00101937]\n",
      " [0.         0.         0.         0.        ]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.794 (26)\n",
      "[[1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.99898063 0.         0.         0.00101937]\n",
      " [0.         0.         0.         0.        ]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.794 (26)\n",
      "[[1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.99898063 0.         0.         0.00101937]\n",
      " [0.         0.         0.         0.        ]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.794 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.793 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.793 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.793 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.792 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.791 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.791 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.791 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.790 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.790 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.790 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.789 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.789 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.789 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.788 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.788 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.787 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.787 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.787 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.786 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.786 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.785 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.785 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.785 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.784 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.784 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.783 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.783 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.782 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.782 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.781 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.781 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.781 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.781 (26)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.780 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.780 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.779 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.779 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.779 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.778 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.778 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.777 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.777 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.776 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.776 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.775 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.775 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.775 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.774 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.774 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.773 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.773 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.772 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.772 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.771 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.771 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.771 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.770 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.770 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.769 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.769 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.768 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.768 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.767 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.767 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.766 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.766 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.765 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.765 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.764 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.764 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.764 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.763 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.763 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.762 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.762 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.761 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.761 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.760 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.760 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.759 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.759 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.758 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.758 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.757 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.757 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.756 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.755 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.755 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.755 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.754 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.753 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.753 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.752 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.752 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.751 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.751 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.750 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.750 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.749 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.748 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.748 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.747 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.747 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.746 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.745 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.745 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.744 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.744 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.743 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.743 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.742 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.742 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.741 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.741 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.740 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.739 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.739 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.738 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.737 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.737 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.736 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.736 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.735 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.734 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.734 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.733 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 2.732 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.732 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.731 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.730 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.730 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.729 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.729 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.728 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.727 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.727 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.726 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.726 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.725 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.724 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.724 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.723 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.722 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.721 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.721 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.720 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.719 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.719 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.718 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.718 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.717 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.716 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.716 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.715 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.714 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.713 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.713 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.712 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.712 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.711 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.711 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.710 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.709 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.708 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.708 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.707 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.706 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.706 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.705 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.704 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.703 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.703 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.703 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.701 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.701 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.700 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.699 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.699 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.698 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.697 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.697 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.696 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.694 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.695 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.694 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.693 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.692 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.692 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.691 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.690 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.690 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.689 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.688 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.688 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.687 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.686 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.685 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.685 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.684 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.683 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.683 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.681 (26)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.681 (26)\n",
      "[[1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [0.99898063 0.         0.00101937]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.680 (26)\n",
      "[[1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [0.99796126 0.         0.00203874]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.680 (26)\n",
      "[[1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [0.99796126 0.         0.00203874]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.678 (26)\n",
      "[[1.        0.        0.       ]\n",
      " [1.        0.        0.       ]\n",
      " [0.9969419 0.        0.0030581]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.678 (26)\n",
      "[[1.        0.        0.       ]\n",
      " [1.        0.        0.       ]\n",
      " [0.9969419 0.        0.0030581]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.677 (26)\n",
      "[[1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [0.99592253 0.         0.00407747]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.676 (26)\n",
      "[[1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [0.99490316 0.         0.00509684]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.676 (26)\n",
      "[[1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [0.99184506 0.         0.00815494]]\n",
      "Train: 0.05, Val: 0.01, Test: 0.01\n",
      "loss 2.674 (26)\n",
      "[[1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [0.98674822 0.         0.01325178]]\n",
      "Train: 0.06, Val: 0.02, Test: 0.02\n",
      "loss 2.674 (26)\n",
      "[[1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [0.98063201 0.         0.01936799]]\n",
      "Train: 0.06, Val: 0.02, Test: 0.02\n",
      "loss 2.674 (26)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [0.97247706 0.         0.02752294]]\n",
      "Train: 0.06, Val: 0.03, Test: 0.02\n",
      "loss 2.673 (26)\n",
      "[[1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [0.97043833 0.         0.02956167]]\n",
      "Train: 0.06, Val: 0.03, Test: 0.02\n",
      "loss 2.672 (26)\n",
      "[[1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [0.96636086 0.         0.03363914]]\n",
      "Train: 0.07, Val: 0.03, Test: 0.03\n",
      "loss 2.671 (26)\n",
      "[[1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [0.96330275 0.         0.03669725]]\n",
      "Train: 0.07, Val: 0.03, Test: 0.03\n",
      "loss 2.670 (26)\n",
      "[[1.         0.         0.        ]\n",
      " [0.875      0.         0.125     ]\n",
      " [0.96228338 0.         0.03771662]]\n",
      "Train: 0.07, Val: 0.03, Test: 0.03\n",
      "loss 2.670 (26)\n",
      "[[1.         0.         0.        ]\n",
      " [0.875      0.         0.125     ]\n",
      " [0.95820591 0.         0.04179409]]\n",
      "Train: 0.07, Val: 0.03, Test: 0.03\n",
      "loss 2.668 (26)\n",
      "[[1.         0.         0.        ]\n",
      " [0.875      0.         0.125     ]\n",
      " [0.95107034 0.         0.04892966]]\n",
      "Train: 0.07, Val: 0.04, Test: 0.03\n",
      "loss 2.668 (26)\n",
      "[[1.         0.         0.        ]\n",
      " [0.875      0.         0.125     ]\n",
      " [0.94189602 0.         0.05810398]]\n",
      "Train: 0.08, Val: 0.04, Test: 0.04\n",
      "loss 2.667 (26)\n",
      "[[1.         0.         0.        ]\n",
      " [0.75       0.         0.25      ]\n",
      " [0.93781855 0.         0.06218145]]\n",
      "Train: 0.08, Val: 0.05, Test: 0.04\n",
      "loss 2.665 (26)\n",
      "[[1.         0.         0.        ]\n",
      " [0.75       0.         0.25      ]\n",
      " [0.93272171 0.         0.06727829]]\n",
      "Train: 0.08, Val: 0.05, Test: 0.05\n",
      "loss 2.666 (26)\n",
      "[[1.         0.         0.        ]\n",
      " [0.75       0.         0.25      ]\n",
      " [0.92456677 0.         0.07543323]]\n",
      "Train: 0.09, Val: 0.06, Test: 0.05\n",
      "loss 2.665 (26)\n",
      "[[1.        0.        0.       ]\n",
      " [0.75      0.        0.25     ]\n",
      " [0.9204893 0.        0.0795107]]\n",
      "Train: 0.09, Val: 0.06, Test: 0.05\n",
      "loss 2.664 (26)\n",
      "[[1.         0.         0.        ]\n",
      " [0.625      0.         0.375     ]\n",
      " [0.91641182 0.         0.08358818]]\n",
      "Train: 0.10, Val: 0.06, Test: 0.06\n",
      "loss 2.663 (26)\n",
      "[[1.         0.         0.        ]\n",
      " [0.625      0.         0.375     ]\n",
      " [0.90723751 0.         0.09276249]]\n",
      "Train: 0.10, Val: 0.07, Test: 0.06\n",
      "loss 2.663 (26)\n",
      "[[1.        0.        0.       ]\n",
      " [0.625     0.        0.375    ]\n",
      " [0.9011213 0.        0.0988787]]\n",
      "Train: 0.11, Val: 0.07, Test: 0.06\n",
      "loss 2.662 (26)\n",
      "[[1.        0.        0.       ]\n",
      " [0.625     0.        0.375    ]\n",
      " [0.8950051 0.        0.1049949]]\n",
      "Train: 0.11, Val: 0.07, Test: 0.07\n",
      "loss 2.660 (26)\n",
      "[[1.         0.         0.        ]\n",
      " [0.5        0.         0.5       ]\n",
      " [0.88888889 0.         0.11111111]]\n",
      "Train: 0.11, Val: 0.08, Test: 0.07\n",
      "loss 2.660 (26)\n",
      "[[1.         0.         0.        ]\n",
      " [0.5        0.         0.5       ]\n",
      " [0.88073394 0.         0.11926606]]\n",
      "Train: 0.12, Val: 0.08, Test: 0.07\n",
      "loss 2.659 (26)\n",
      "[[1.         0.         0.        ]\n",
      " [0.5        0.         0.5       ]\n",
      " [0.87155963 0.         0.12844037]]\n",
      "Train: 0.12, Val: 0.08, Test: 0.08\n",
      "loss 2.658 (26)\n",
      "[[1.         0.         0.        ]\n",
      " [0.5        0.         0.5       ]\n",
      " [0.86748216 0.         0.13251784]]\n",
      "Train: 0.13, Val: 0.09, Test: 0.08\n",
      "loss 2.658 (26)\n",
      "[[1.         0.         0.        ]\n",
      " [0.5        0.         0.5       ]\n",
      " [0.85830785 0.         0.14169215]]\n",
      "Train: 0.13, Val: 0.09, Test: 0.09\n",
      "loss 2.656 (26)\n",
      "[[1.         0.         0.        ]\n",
      " [0.5        0.         0.5       ]\n",
      " [0.85321101 0.         0.14678899]]\n",
      "Train: 0.13, Val: 0.09, Test: 0.09\n",
      "loss 2.657 (26)\n",
      "[[0.91666667 0.         0.08333333]\n",
      " [0.5        0.         0.5       ]\n",
      " [0.84607543 0.         0.15392457]]\n",
      "Train: 0.14, Val: 0.10, Test: 0.10\n",
      "loss 2.655 (26)\n",
      "[[0.91666667 0.         0.08333333]\n",
      " [0.375      0.         0.625     ]\n",
      " [0.83486239 0.         0.16513761]]\n",
      "Train: 0.14, Val: 0.10, Test: 0.10\n",
      "loss 2.654 (26)\n",
      "[[0.91666667 0.         0.08333333]\n",
      " [0.375      0.         0.625     ]\n",
      " [0.8216106  0.         0.1783894 ]]\n",
      "Train: 0.15, Val: 0.11, Test: 0.11\n",
      "loss 2.654 (26)\n",
      "[[0.91666667 0.         0.08333333]\n",
      " [0.25       0.         0.75      ]\n",
      " [0.81447503 0.         0.18552497]]\n",
      "Train: 0.15, Val: 0.11, Test: 0.11\n",
      "loss 2.653 (26)\n",
      "[[0.91666667 0.         0.08333333]\n",
      " [0.25       0.         0.75      ]\n",
      " [0.81141692 0.         0.18858308]]\n",
      "Train: 0.16, Val: 0.11, Test: 0.12\n",
      "loss 2.653 (26)\n",
      "[[0.91666667 0.         0.08333333]\n",
      " [0.25       0.         0.75      ]\n",
      " [0.80428135 0.         0.19571865]]\n",
      "Train: 0.16, Val: 0.12, Test: 0.12\n",
      "loss 2.651 (26)\n",
      "[[0.91666667 0.         0.08333333]\n",
      " [0.25       0.         0.75      ]\n",
      " [0.80020387 0.         0.19979613]]\n",
      "Train: 0.16, Val: 0.12, Test: 0.12\n",
      "loss 2.650 (26)\n",
      "[[0.91666667 0.         0.08333333]\n",
      " [0.25       0.         0.75      ]\n",
      " [0.7930683  0.         0.2069317 ]]\n",
      "Train: 0.16, Val: 0.12, Test: 0.12\n",
      "loss 2.649 (26)\n",
      "[[0.83333333 0.         0.16666667]\n",
      " [0.25       0.         0.75      ]\n",
      " [0.78797146 0.         0.21202854]]\n",
      "Train: 0.17, Val: 0.12, Test: 0.13\n",
      "loss 2.649 (26)\n",
      "[[0.83333333 0.         0.16666667]\n",
      " [0.25       0.         0.75      ]\n",
      " [0.77879715 0.         0.22120285]]\n",
      "Train: 0.17, Val: 0.13, Test: 0.13\n",
      "loss 2.647 (26)\n",
      "[[0.75       0.         0.25      ]\n",
      " [0.25       0.         0.75      ]\n",
      " [0.77268094 0.         0.22731906]]\n",
      "Train: 0.17, Val: 0.13, Test: 0.13\n",
      "loss 2.646 (26)\n",
      "[[0.75       0.         0.25      ]\n",
      " [0.25       0.         0.75      ]\n",
      " [0.76860347 0.         0.23139653]]\n",
      "Train: 0.18, Val: 0.13, Test: 0.13\n",
      "loss 2.645 (26)\n",
      "[[0.75       0.         0.25      ]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.76044852 0.         0.23955148]]\n",
      "Train: 0.18, Val: 0.14, Test: 0.13\n",
      "loss 2.645 (26)\n",
      "[[0.75       0.         0.25      ]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.75229358 0.         0.24770642]]\n",
      "Train: 0.18, Val: 0.14, Test: 0.14\n",
      "loss 2.644 (26)\n",
      "[[0.66666667 0.         0.33333333]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.74413863 0.         0.25586137]]\n",
      "Train: 0.18, Val: 0.14, Test: 0.14\n",
      "loss 2.643 (26)\n",
      "[[0.58333333 0.         0.41666667]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.74108053 0.         0.25891947]]\n",
      "Train: 0.19, Val: 0.14, Test: 0.14\n",
      "loss 2.642 (26)\n",
      "[[0.58333333 0.         0.41666667]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.73598369 0.         0.26401631]]\n",
      "Train: 0.18, Val: 0.14, Test: 0.14\n",
      "loss 2.641 (26)\n",
      "[[0.58333333 0.         0.41666667]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.72884811 0.         0.27115189]]\n",
      "Train: 0.19, Val: 0.15, Test: 0.15\n",
      "loss 2.640 (26)\n",
      "[[0.58333333 0.         0.41666667]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.72273191 0.         0.27726809]]\n",
      "Train: 0.19, Val: 0.15, Test: 0.15\n",
      "loss 2.640 (26)\n",
      "[[0.58333333 0.         0.41666667]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.7196738  0.         0.2803262 ]]\n",
      "Train: 0.19, Val: 0.15, Test: 0.15\n",
      "loss 2.639 (26)\n",
      "[[0.58333333 0.         0.41666667]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.71355759 0.         0.28644241]]\n",
      "Train: 0.19, Val: 0.15, Test: 0.15\n",
      "loss 2.637 (26)\n",
      "[[0.58333333 0.         0.41666667]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.70948012 0.         0.29051988]]\n",
      "Train: 0.20, Val: 0.16, Test: 0.16\n",
      "loss 2.636 (26)\n",
      "[[0.58333333 0.         0.41666667]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.70642202 0.         0.29357798]]\n",
      "Train: 0.20, Val: 0.16, Test: 0.16\n",
      "loss 2.636 (26)\n",
      "[[0.58333333 0.         0.41666667]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.69826707 0.         0.30173293]]\n",
      "Train: 0.20, Val: 0.16, Test: 0.16\n",
      "loss 2.635 (26)\n",
      "[[0.58333333 0.         0.41666667]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.69317023 0.         0.30682977]]\n",
      "Train: 0.20, Val: 0.16, Test: 0.16\n",
      "loss 2.634 (26)\n",
      "[[0.58333333 0.         0.41666667]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.68399592 0.         0.31600408]]\n",
      "Train: 0.20, Val: 0.17, Test: 0.16\n",
      "loss 2.633 (26)\n",
      "[[0.58333333 0.         0.41666667]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.67787971 0.         0.32212029]]\n",
      "Train: 0.20, Val: 0.17, Test: 0.17\n",
      "loss 2.632 (26)\n",
      "[[0.58333333 0.         0.41666667]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.67176351 0.         0.32823649]]\n",
      "Train: 0.21, Val: 0.17, Test: 0.17\n",
      "loss 2.632 (26)\n",
      "[[0.58333333 0.         0.41666667]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.6687054  0.         0.3312946 ]]\n",
      "Train: 0.21, Val: 0.17, Test: 0.17\n",
      "loss 2.631 (26)\n",
      "[[0.58333333 0.         0.41666667]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.66156983 0.         0.33843017]]\n",
      "Train: 0.21, Val: 0.17, Test: 0.17\n",
      "loss 2.629 (26)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.58333333 0.         0.41666667]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.65239551 0.         0.34760449]]\n",
      "Train: 0.21, Val: 0.18, Test: 0.17\n",
      "loss 2.628 (26)\n",
      "[[0.58333333 0.         0.41666667]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.64729867 0.         0.35270133]]\n",
      "Train: 0.21, Val: 0.18, Test: 0.18\n",
      "loss 2.627 (26)\n",
      "[[0.58333333 0.         0.41666667]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.64118247 0.         0.35881753]]\n",
      "Train: 0.22, Val: 0.18, Test: 0.18\n",
      "loss 2.626 (26)\n",
      "[[0.58333333 0.         0.41666667]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.63404689 0.         0.36595311]]\n",
      "Train: 0.22, Val: 0.18, Test: 0.18\n",
      "loss 2.625 (26)\n",
      "[[0.58333333 0.         0.41666667]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.62793068 0.         0.37206932]]\n",
      "Train: 0.22, Val: 0.19, Test: 0.18\n",
      "loss 2.624 (26)\n",
      "[[0.5        0.         0.5       ]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.62385321 0.         0.37614679]]\n",
      "Train: 0.22, Val: 0.19, Test: 0.19\n",
      "loss 2.623 (26)\n",
      "[[0.5        0.         0.5       ]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.61060143 0.         0.38939857]]\n",
      "Train: 0.23, Val: 0.19, Test: 0.19\n",
      "loss 2.622 (26)\n",
      "[[0.5        0.         0.5       ]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.60754332 0.         0.39245668]]\n",
      "Train: 0.23, Val: 0.19, Test: 0.19\n",
      "loss 2.622 (26)\n",
      "[[0.5        0.         0.5       ]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.60346585 0.         0.39653415]]\n",
      "Train: 0.23, Val: 0.19, Test: 0.19\n",
      "loss 2.620 (26)\n",
      "[[0.5        0.         0.5       ]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.59633028 0.         0.40366972]]\n",
      "Train: 0.23, Val: 0.20, Test: 0.19\n",
      "loss 2.620 (26)\n",
      "[[0.5        0.         0.5       ]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.59531091 0.         0.40468909]]\n",
      "Train: 0.23, Val: 0.20, Test: 0.20\n",
      "loss 2.619 (26)\n",
      "[[0.5        0.         0.5       ]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.59123344 0.         0.40876656]]\n",
      "Train: 0.23, Val: 0.20, Test: 0.20\n",
      "loss 2.618 (26)\n",
      "[[0.5        0.         0.5       ]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.58409786 0.         0.41590214]]\n",
      "Train: 0.23, Val: 0.20, Test: 0.20\n",
      "loss 2.616 (26)\n",
      "[[0.5        0.         0.5       ]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.57798165 0.         0.42201835]]\n",
      "Train: 0.24, Val: 0.20, Test: 0.20\n",
      "loss 2.615 (26)\n",
      "[[0.5        0.         0.5       ]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.57288481 0.         0.42711519]]\n",
      "Train: 0.24, Val: 0.20, Test: 0.20\n",
      "loss 2.614 (26)\n",
      "[[0.5        0.         0.5       ]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.56778797 0.         0.43221203]]\n",
      "Train: 0.24, Val: 0.21, Test: 0.21\n",
      "loss 2.613 (26)\n",
      "[[0.5        0.         0.5       ]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.55555556 0.         0.44444444]]\n",
      "Train: 0.24, Val: 0.21, Test: 0.21\n",
      "loss 2.612 (26)\n",
      "[[0.5        0.         0.5       ]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.54841998 0.         0.45158002]]\n",
      "Train: 0.25, Val: 0.21, Test: 0.21\n",
      "loss 2.612 (26)\n",
      "[[0.5        0.         0.5       ]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.54230377 0.         0.45769623]]\n",
      "Train: 0.25, Val: 0.21, Test: 0.21\n",
      "loss 2.610 (26)\n",
      "[[0.5        0.         0.5       ]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.53720693 0.         0.46279307]]\n",
      "Train: 0.25, Val: 0.22, Test: 0.21\n",
      "loss 2.609 (26)\n",
      "[[0.5        0.         0.5       ]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.53618756 0.         0.46381244]]\n",
      "Train: 0.25, Val: 0.22, Test: 0.22\n",
      "loss 2.607 (26)\n",
      "[[0.5        0.         0.5       ]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.53007136 0.         0.46992864]]\n",
      "Train: 0.25, Val: 0.22, Test: 0.22\n",
      "loss 2.607 (26)\n",
      "[[0.5        0.         0.5       ]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.52803262 0.         0.47196738]]\n",
      "Train: 0.25, Val: 0.22, Test: 0.22\n",
      "loss 2.606 (26)\n",
      "[[0.5        0.         0.5       ]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.52089704 0.         0.47910296]]\n",
      "Train: 0.25, Val: 0.22, Test: 0.22\n",
      "loss 2.605 (26)\n",
      "[[0.41666667 0.         0.58333333]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.5158002  0.         0.4841998 ]]\n",
      "Train: 0.26, Val: 0.22, Test: 0.22\n",
      "loss 2.604 (26)\n",
      "[[0.41666667 0.         0.58333333]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.51478084 0.         0.48521916]]\n",
      "Train: 0.26, Val: 0.22, Test: 0.22\n",
      "loss 2.602 (26)\n",
      "[[0.41666667 0.         0.58333333]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.50764526 0.         0.49235474]]\n",
      "Train: 0.26, Val: 0.22, Test: 0.22\n",
      "loss 2.601 (26)\n",
      "[[0.41666667 0.         0.58333333]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.50356779 0.         0.49643221]]\n",
      "Train: 0.26, Val: 0.23, Test: 0.22\n",
      "loss 2.601 (26)\n",
      "[[0.41666667 0.         0.58333333]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.49745158 0.         0.50254842]]\n",
      "Train: 0.26, Val: 0.23, Test: 0.22\n",
      "loss 2.599 (26)\n",
      "[[0.41666667 0.         0.58333333]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.49541284 0.         0.50458716]]\n",
      "Train: 0.26, Val: 0.23, Test: 0.22\n",
      "loss 2.597 (26)\n",
      "[[0.41666667 0.         0.58333333]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.48929664 0.         0.51070336]]\n",
      "Train: 0.26, Val: 0.23, Test: 0.23\n",
      "loss 2.597 (26)\n",
      "[[0.41666667 0.         0.58333333]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.4872579  0.         0.5127421 ]]\n",
      "Train: 0.26, Val: 0.23, Test: 0.23\n",
      "loss 2.595 (26)\n",
      "[[0.41666667 0.         0.58333333]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.47910296 0.         0.52089704]]\n",
      "Train: 0.27, Val: 0.23, Test: 0.23\n",
      "loss 2.595 (26)\n",
      "[[0.41666667 0.         0.58333333]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.47604485 0.         0.52395515]]\n",
      "Train: 0.27, Val: 0.23, Test: 0.23\n",
      "loss 2.594 (26)\n",
      "[[0.41666667 0.         0.58333333]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.47298675 0.         0.52701325]]\n",
      "Train: 0.27, Val: 0.23, Test: 0.23\n",
      "loss 2.592 (26)\n",
      "[[0.41666667 0.         0.58333333]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.46687054 0.         0.53312946]]\n",
      "Train: 0.27, Val: 0.24, Test: 0.23\n",
      "loss 2.592 (26)\n",
      "[[0.41666667 0.         0.58333333]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.4617737  0.         0.5382263 ]]\n",
      "Train: 0.27, Val: 0.24, Test: 0.24\n",
      "loss 2.590 (26)\n",
      "[[0.41666667 0.         0.58333333]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.45667686 0.         0.54332314]]\n",
      "Train: 0.27, Val: 0.24, Test: 0.24\n",
      "loss 2.588 (26)\n",
      "[[0.41666667 0.         0.58333333]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.45565749 0.         0.54434251]]\n",
      "Train: 0.28, Val: 0.24, Test: 0.24\n",
      "loss 2.588 (26)\n",
      "[[0.41666667 0.         0.58333333]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.45259939 0.         0.54740061]]\n",
      "Train: 0.28, Val: 0.24, Test: 0.24\n",
      "loss 2.586 (26)\n",
      "[[0.41666667 0.         0.58333333]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.44648318 0.         0.55351682]]\n",
      "Train: 0.28, Val: 0.24, Test: 0.24\n",
      "loss 2.585 (26)\n",
      "[[0.41666667 0.         0.58333333]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.44444444 0.         0.55555556]]\n",
      "Train: 0.28, Val: 0.24, Test: 0.24\n",
      "loss 2.584 (26)\n",
      "[[0.41666667 0.         0.58333333]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.43730887 0.         0.56269113]]\n",
      "Train: 0.28, Val: 0.25, Test: 0.24\n",
      "loss 2.582 (26)\n",
      "[[0.41666667 0.         0.58333333]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.43119266 0.         0.56880734]]\n",
      "Train: 0.28, Val: 0.25, Test: 0.25\n",
      "loss 2.581 (26)\n",
      "[[0.41666667 0.         0.58333333]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.42405708 0.         0.57594292]]\n",
      "Train: 0.28, Val: 0.25, Test: 0.25\n",
      "loss 2.580 (26)\n",
      "[[0.41666667 0.         0.58333333]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.41896024 0.         0.58103976]]\n",
      "Train: 0.28, Val: 0.25, Test: 0.25\n",
      "loss 2.579 (26)\n",
      "[[0.41666667 0.         0.58333333]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.41284404 0.         0.58715596]]\n",
      "Train: 0.28, Val: 0.25, Test: 0.25\n",
      "loss 2.578 (26)\n",
      "[[0.41666667 0.         0.58333333]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.4077472  0.         0.5922528 ]]\n",
      "Train: 0.28, Val: 0.25, Test: 0.25\n",
      "loss 2.575 (26)\n",
      "[[0.41666667 0.         0.58333333]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.40366972 0.         0.59633028]]\n",
      "Train: 0.29, Val: 0.25, Test: 0.25\n",
      "loss 2.575 (26)\n",
      "[[0.41666667 0.         0.58333333]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.40061162 0.         0.59938838]]\n",
      "Train: 0.29, Val: 0.26, Test: 0.25\n",
      "loss 2.574 (26)\n",
      "[[0.41666667 0.         0.58333333]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.39551478 0.         0.60448522]]\n",
      "Train: 0.29, Val: 0.26, Test: 0.25\n",
      "loss 2.573 (26)\n",
      "[[0.41666667 0.         0.58333333]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.39449541 0.         0.60550459]]\n",
      "Train: 0.29, Val: 0.26, Test: 0.25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 2.572 (26)\n",
      "[[0.41666667 0.         0.58333333]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.39347604 0.         0.60652396]]\n",
      "Train: 0.29, Val: 0.26, Test: 0.25\n",
      "loss 2.569 (26)\n",
      "[[0.41666667 0.         0.58333333]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.39041794 0.         0.60958206]]\n",
      "Train: 0.29, Val: 0.26, Test: 0.25\n",
      "loss 2.568 (26)\n",
      "[[0.41666667 0.         0.58333333]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.38634047 0.         0.61365953]]\n",
      "Train: 0.29, Val: 0.26, Test: 0.25\n",
      "loss 2.567 (26)\n",
      "[[0.41666667 0.         0.58333333]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.38022426 0.         0.61977574]]\n",
      "Train: 0.29, Val: 0.26, Test: 0.26\n",
      "loss 2.567 (26)\n",
      "[[0.41666667 0.         0.58333333]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.37308869 0.         0.62691131]]\n",
      "Train: 0.29, Val: 0.26, Test: 0.26\n",
      "loss 2.565 (26)\n",
      "[[0.41666667 0.         0.58333333]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.36901121 0.         0.63098879]]\n",
      "Train: 0.29, Val: 0.26, Test: 0.26\n",
      "loss 2.563 (26)\n",
      "[[0.41666667 0.         0.58333333]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.36493374 0.         0.63506626]]\n",
      "Train: 0.29, Val: 0.27, Test: 0.26\n",
      "loss 2.563 (26)\n",
      "[[0.41666667 0.         0.58333333]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.36187564 0.         0.63812436]]\n",
      "Train: 0.29, Val: 0.27, Test: 0.26\n",
      "loss 2.561 (26)\n",
      "[[0.41666667 0.         0.58333333]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.35474006 0.         0.64525994]]\n",
      "Train: 0.29, Val: 0.27, Test: 0.26\n",
      "loss 2.560 (26)\n",
      "[[0.41666667 0.         0.58333333]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.35474006 0.         0.64525994]]\n",
      "Train: 0.29, Val: 0.27, Test: 0.26\n",
      "loss 2.559 (26)\n",
      "[[0.41666667 0.         0.58333333]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.35168196 0.         0.64831804]]\n",
      "Train: 0.29, Val: 0.27, Test: 0.26\n",
      "loss 2.557 (26)\n",
      "[[0.41666667 0.         0.58333333]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.34862385 0.         0.65137615]]\n",
      "Train: 0.29, Val: 0.27, Test: 0.26\n",
      "loss 2.557 (26)\n",
      "[[0.41666667 0.         0.58333333]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.34760449 0.         0.65239551]]\n",
      "Train: 0.30, Val: 0.27, Test: 0.27\n",
      "loss 2.555 (26)\n",
      "[[0.41666667 0.         0.58333333]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.34046891 0.         0.65953109]]\n",
      "Train: 0.30, Val: 0.27, Test: 0.27\n",
      "loss 2.553 (26)\n",
      "[[0.41666667 0.         0.58333333]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.33741081 0.         0.66258919]]\n",
      "Train: 0.30, Val: 0.27, Test: 0.27\n",
      "loss 2.551 (26)\n",
      "[[0.41666667 0.         0.58333333]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.3343527  0.         0.6656473 ]]\n",
      "Train: 0.30, Val: 0.27, Test: 0.27\n",
      "loss 2.549 (26)\n",
      "[[0.41666667 0.         0.58333333]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.33027523 0.         0.66972477]]\n",
      "Train: 0.30, Val: 0.27, Test: 0.27\n",
      "loss 2.550 (26)\n",
      "[[0.33333333 0.         0.66666667]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.32823649 0.         0.67176351]]\n",
      "Train: 0.30, Val: 0.27, Test: 0.27\n",
      "loss 2.547 (26)\n",
      "[[0.33333333 0.         0.66666667]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.32619776 0.         0.67380224]]\n",
      "Train: 0.30, Val: 0.27, Test: 0.27\n",
      "loss 2.546 (26)\n",
      "[[0.33333333 0.         0.66666667]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.32212029 0.         0.67787971]]\n",
      "Train: 0.30, Val: 0.27, Test: 0.27\n",
      "loss 2.545 (26)\n",
      "[[0.25       0.         0.75      ]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.32008155 0.         0.67991845]]\n",
      "Train: 0.30, Val: 0.27, Test: 0.27\n",
      "loss 2.542 (26)\n",
      "[[0.25       0.         0.75      ]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.31702345 0.         0.68297655]]\n",
      "Train: 0.31, Val: 0.27, Test: 0.27\n",
      "loss 2.543 (26)\n",
      "[[0.25       0.         0.75      ]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.31294597 0.         0.68705403]]\n",
      "Train: 0.31, Val: 0.28, Test: 0.27\n",
      "loss 2.540 (26)\n",
      "[[0.25       0.         0.75      ]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.31192661 0.         0.68807339]]\n",
      "Train: 0.31, Val: 0.28, Test: 0.28\n",
      "loss 2.540 (26)\n",
      "[[0.25       0.         0.75      ]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.30784913 0.         0.69215087]]\n",
      "Train: 0.31, Val: 0.28, Test: 0.28\n",
      "loss 2.536 (26)\n",
      "[[0.25       0.         0.75      ]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.30377166 0.         0.69622834]]\n",
      "Train: 0.31, Val: 0.28, Test: 0.28\n",
      "loss 2.537 (26)\n",
      "[[0.25       0.         0.75      ]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.30071356 0.         0.69928644]]\n",
      "Train: 0.31, Val: 0.28, Test: 0.28\n",
      "loss 2.534 (26)\n",
      "[[0.25       0.         0.75      ]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.29663609 0.         0.70336391]]\n",
      "Train: 0.31, Val: 0.28, Test: 0.28\n",
      "loss 2.532 (26)\n",
      "[[0.25       0.         0.75      ]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.29561672 0.         0.70438328]]\n",
      "Train: 0.31, Val: 0.28, Test: 0.28\n",
      "loss 2.531 (26)\n",
      "[[0.25       0.         0.75      ]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.29153925 0.         0.70846075]]\n",
      "Train: 0.31, Val: 0.28, Test: 0.28\n",
      "loss 2.530 (26)\n",
      "[[0.25       0.         0.75      ]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.29051988 0.         0.70948012]]\n",
      "Train: 0.31, Val: 0.28, Test: 0.28\n",
      "loss 2.527 (26)\n",
      "[[0.25       0.         0.75      ]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.28644241 0.         0.71355759]]\n",
      "Train: 0.31, Val: 0.28, Test: 0.28\n",
      "loss 2.527 (26)\n",
      "[[0.25       0.         0.75      ]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.28542304 0.         0.71457696]]\n",
      "Train: 0.31, Val: 0.28, Test: 0.28\n",
      "loss 2.526 (26)\n",
      "[[0.25       0.         0.75      ]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.28134557 0.         0.71865443]]\n",
      "Train: 0.31, Val: 0.28, Test: 0.28\n",
      "loss 2.524 (26)\n",
      "[[0.25      0.        0.75     ]\n",
      " [0.125     0.        0.875    ]\n",
      " [0.2803262 0.        0.7196738]]\n",
      "Train: 0.31, Val: 0.28, Test: 0.28\n",
      "loss 2.523 (26)\n",
      "[[0.25       0.         0.75      ]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.27726809 0.         0.72273191]]\n",
      "Train: 0.31, Val: 0.28, Test: 0.28\n",
      "loss 2.519 (26)\n",
      "[[0.25       0.         0.75      ]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.27624873 0.         0.72375127]]\n",
      "Train: 0.31, Val: 0.28, Test: 0.28\n",
      "loss 2.521 (26)\n",
      "[[0.25       0.         0.75      ]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.27319062 0.         0.72680938]]\n",
      "Train: 0.31, Val: 0.29, Test: 0.28\n",
      "loss 2.517 (26)\n",
      "[[0.25       0.         0.75      ]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.27319062 0.         0.72680938]]\n",
      "Train: 0.31, Val: 0.29, Test: 0.28\n",
      "loss 2.517 (26)\n",
      "[[0.25       0.         0.75      ]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.27115189 0.         0.72884811]]\n",
      "Train: 0.31, Val: 0.29, Test: 0.28\n",
      "loss 2.514 (26)\n",
      "[[0.25       0.         0.75      ]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.26809378 0.         0.73190622]]\n",
      "Train: 0.30, Val: 0.29, Test: 0.28\n",
      "loss 2.514 (26)\n",
      "[[0.25       0.         0.75      ]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.26299694 0.         0.73700306]]\n",
      "Train: 0.30, Val: 0.29, Test: 0.28\n",
      "loss 2.511 (26)\n",
      "[[0.25       0.         0.75      ]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.26197757 0.         0.73802243]]\n",
      "Train: 0.30, Val: 0.29, Test: 0.28\n",
      "loss 2.509 (26)\n",
      "[[0.25       0.         0.75      ]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.25891947 0.         0.74108053]]\n",
      "Train: 0.30, Val: 0.29, Test: 0.28\n",
      "loss 2.507 (26)\n",
      "[[0.25       0.         0.75      ]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.25586137 0.         0.74413863]]\n",
      "Train: 0.31, Val: 0.29, Test: 0.28\n",
      "loss 2.506 (26)\n",
      "[[0.25       0.         0.75      ]\n",
      " [0.125      0.         0.875     ]\n",
      " [0.25586137 0.         0.74413863]]\n",
      "Train: 0.31, Val: 0.29, Test: 0.28\n",
      "loss 2.505 (26)\n",
      "[[0.16666667 0.         0.83333333]\n",
      " [0.         0.         1.        ]\n",
      " [0.25586137 0.         0.74413863]]\n",
      "Train: 0.31, Val: 0.29, Test: 0.28\n",
      "loss 2.503 (26)\n",
      "[[0.16666667 0.         0.83333333]\n",
      " [0.         0.         1.        ]\n",
      " [0.25076453 0.         0.74923547]]\n",
      "Train: 0.31, Val: 0.29, Test: 0.28\n",
      "loss 2.501 (26)\n",
      "[[0.16666667 0.         0.83333333]\n",
      " [0.         0.         1.        ]\n",
      " [0.24974516 0.         0.75025484]]\n",
      "Train: 0.31, Val: 0.29, Test: 0.28\n",
      "loss 2.500 (26)\n",
      "[[0.16666667 0.         0.83333333]\n",
      " [0.         0.         1.        ]\n",
      " [0.24872579 0.         0.75127421]]\n",
      "Train: 0.31, Val: 0.29, Test: 0.28\n",
      "loss 2.499 (26)\n",
      "[[0.16666667 0.         0.83333333]\n",
      " [0.         0.         1.        ]\n",
      " [0.24872579 0.         0.75127421]]\n",
      "Train: 0.31, Val: 0.29, Test: 0.29\n",
      "loss 2.497 (26)\n",
      "[[0.16666667 0.         0.83333333]\n",
      " [0.         0.         1.        ]\n",
      " [0.24668705 0.         0.75331295]]\n",
      "Train: 0.31, Val: 0.29, Test: 0.29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 2.495 (26)\n",
      "[[0.16666667 0.         0.83333333]\n",
      " [0.         0.         1.        ]\n",
      " [0.24362895 0.         0.75637105]]\n",
      "Train: 0.31, Val: 0.29, Test: 0.29\n",
      "loss 2.495 (26)\n",
      "[[0.16666667 0.         0.83333333]\n",
      " [0.         0.         1.        ]\n",
      " [0.23955148 0.         0.76044852]]\n",
      "Train: 0.31, Val: 0.29, Test: 0.29\n",
      "loss 2.491 (26)\n",
      "[[0.16666667 0.         0.83333333]\n",
      " [0.         0.         1.        ]\n",
      " [0.23751274 0.         0.76248726]]\n",
      "Train: 0.31, Val: 0.29, Test: 0.29\n",
      "loss 2.491 (26)\n",
      "[[0.16666667 0.         0.83333333]\n",
      " [0.         0.         1.        ]\n",
      " [0.23547401 0.         0.76452599]]\n",
      "Train: 0.31, Val: 0.29, Test: 0.29\n",
      "loss 2.488 (26)\n",
      "[[0.16666667 0.         0.83333333]\n",
      " [0.         0.         1.        ]\n",
      " [0.23445464 0.         0.76554536]]\n",
      "Train: 0.31, Val: 0.29, Test: 0.29\n",
      "loss 2.486 (26)\n",
      "[[0.16666667 0.         0.83333333]\n",
      " [0.         0.         1.        ]\n",
      " [0.23343527 0.         0.76656473]]\n",
      "Train: 0.31, Val: 0.29, Test: 0.29\n",
      "loss 2.483 (26)\n",
      "[[0.16666667 0.         0.83333333]\n",
      " [0.         0.         1.        ]\n",
      " [0.2324159  0.         0.7675841 ]]\n",
      "Train: 0.31, Val: 0.29, Test: 0.29\n",
      "loss 2.483 (26)\n",
      "[[0.16666667 0.         0.83333333]\n",
      " [0.         0.         1.        ]\n",
      " [0.23139653 0.         0.76860347]]\n",
      "Train: 0.32, Val: 0.29, Test: 0.29\n",
      "loss 2.480 (26)\n",
      "[[0.16666667 0.         0.83333333]\n",
      " [0.         0.         1.        ]\n",
      " [0.2293578  0.         0.7706422 ]]\n",
      "Train: 0.31, Val: 0.29, Test: 0.29\n",
      "loss 2.480 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.22833843 0.         0.77166157]]\n",
      "Train: 0.31, Val: 0.29, Test: 0.29\n",
      "loss 2.479 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.22629969 0.         0.77370031]]\n",
      "Train: 0.31, Val: 0.29, Test: 0.29\n",
      "loss 2.477 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.22528033 0.         0.77471967]]\n",
      "Train: 0.31, Val: 0.29, Test: 0.29\n",
      "loss 2.474 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.22324159 0.         0.77675841]]\n",
      "Train: 0.31, Val: 0.29, Test: 0.29\n",
      "loss 2.473 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.22222222 0.         0.77777778]]\n",
      "Train: 0.31, Val: 0.29, Test: 0.29\n",
      "loss 2.471 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.22120285 0.         0.77879715]]\n",
      "Train: 0.31, Val: 0.29, Test: 0.29\n",
      "loss 2.469 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.22120285 0.         0.77879715]]\n",
      "Train: 0.31, Val: 0.29, Test: 0.29\n",
      "loss 2.466 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.21814475 0.         0.78185525]]\n",
      "Train: 0.31, Val: 0.29, Test: 0.29\n",
      "loss 2.466 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.21610601 0.         0.78389399]]\n",
      "Train: 0.31, Val: 0.29, Test: 0.29\n",
      "loss 2.463 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.21304791 0.         0.78695209]]\n",
      "Train: 0.32, Val: 0.29, Test: 0.30\n",
      "loss 2.460 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.20795107 0.         0.79204893]]\n",
      "Train: 0.31, Val: 0.29, Test: 0.30\n",
      "loss 2.460 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.2069317  0.         0.7930683 ]]\n",
      "Train: 0.31, Val: 0.29, Test: 0.30\n",
      "loss 2.458 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.2038736  0.         0.7961264 ]]\n",
      "Train: 0.31, Val: 0.30, Test: 0.30\n",
      "loss 2.457 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.2038736  0.         0.7961264 ]]\n",
      "Train: 0.31, Val: 0.30, Test: 0.30\n",
      "loss 2.453 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.20285423 0.         0.79714577]]\n",
      "Train: 0.31, Val: 0.30, Test: 0.30\n",
      "loss 2.454 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.19877676 0.         0.80122324]]\n",
      "Train: 0.31, Val: 0.30, Test: 0.30\n",
      "loss 2.450 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.19775739 0.         0.80224261]]\n",
      "Train: 0.31, Val: 0.30, Test: 0.30\n",
      "loss 2.448 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.19571865 0.         0.80428135]]\n",
      "Train: 0.31, Val: 0.30, Test: 0.30\n",
      "loss 2.446 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.19469929 0.         0.80530071]]\n",
      "Train: 0.31, Val: 0.30, Test: 0.30\n",
      "loss 2.444 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.19062181 0.         0.80937819]]\n",
      "Train: 0.31, Val: 0.30, Test: 0.30\n",
      "loss 2.443 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.19062181 0.         0.80937819]]\n",
      "Train: 0.31, Val: 0.30, Test: 0.30\n",
      "loss 2.441 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.18858308 0.         0.81141692]]\n",
      "Train: 0.31, Val: 0.30, Test: 0.30\n",
      "loss 2.439 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.18450561 0.         0.81549439]]\n",
      "Train: 0.31, Val: 0.30, Test: 0.30\n",
      "loss 2.436 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.1814475  0.         0.8185525 ]]\n",
      "Train: 0.31, Val: 0.30, Test: 0.30\n",
      "loss 2.436 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.1814475  0.         0.8185525 ]]\n",
      "Train: 0.31, Val: 0.30, Test: 0.30\n",
      "loss 2.432 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.1783894  0.         0.8216106 ]]\n",
      "Train: 0.31, Val: 0.30, Test: 0.30\n",
      "loss 2.431 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.1783894  0.         0.8216106 ]]\n",
      "Train: 0.31, Val: 0.30, Test: 0.30\n",
      "loss 2.430 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.17635066 0.         0.82364934]]\n",
      "Train: 0.32, Val: 0.30, Test: 0.30\n",
      "loss 2.428 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.17431193 0.         0.82568807]]\n",
      "Train: 0.32, Val: 0.30, Test: 0.30\n",
      "loss 2.425 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.17431193 0.         0.82568807]]\n",
      "Train: 0.32, Val: 0.30, Test: 0.30\n",
      "loss 2.423 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.17431193 0.         0.82568807]]\n",
      "Train: 0.32, Val: 0.30, Test: 0.30\n",
      "loss 2.421 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.16819572 0.         0.83180428]]\n",
      "Train: 0.32, Val: 0.30, Test: 0.30\n",
      "loss 2.420 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.16819572 0.         0.83180428]]\n",
      "Train: 0.32, Val: 0.30, Test: 0.30\n",
      "loss 2.418 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.16717635 0.         0.83282365]]\n",
      "Train: 0.32, Val: 0.30, Test: 0.30\n",
      "loss 2.416 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.16411825 0.         0.83588175]]\n",
      "Train: 0.32, Val: 0.30, Test: 0.30\n",
      "loss 2.413 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.16411825 0.         0.83588175]]\n",
      "Train: 0.32, Val: 0.30, Test: 0.31\n",
      "loss 2.411 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.16106014 0.         0.83893986]]\n",
      "Train: 0.32, Val: 0.30, Test: 0.31\n",
      "loss 2.410 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.15698267 0.         0.84301733]]\n",
      "Train: 0.31, Val: 0.31, Test: 0.31\n",
      "loss 2.406 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.15698267 0.         0.84301733]]\n",
      "Train: 0.32, Val: 0.31, Test: 0.31\n",
      "loss 2.403 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.15494393 0.         0.84505607]]\n",
      "Train: 0.32, Val: 0.31, Test: 0.31\n",
      "loss 2.403 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.15188583 0.         0.84811417]]\n",
      "Train: 0.32, Val: 0.31, Test: 0.31\n",
      "loss 2.400 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.14780836 0.         0.85219164]]\n",
      "Train: 0.32, Val: 0.31, Test: 0.31\n",
      "loss 2.398 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.14475025 0.         0.85524975]]\n",
      "Train: 0.32, Val: 0.31, Test: 0.31\n",
      "loss 2.397 (26)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.14169215 0.         0.85830785]]\n",
      "Train: 0.31, Val: 0.31, Test: 0.31\n",
      "loss 2.394 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.13965341 0.         0.86034659]]\n",
      "Train: 0.31, Val: 0.31, Test: 0.31\n",
      "loss 2.394 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.13761468 0.         0.86238532]]\n",
      "Train: 0.31, Val: 0.31, Test: 0.31\n",
      "loss 2.389 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.13353721 0.         0.86646279]]\n",
      "Train: 0.31, Val: 0.31, Test: 0.31\n",
      "loss 2.386 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.13251784 0.         0.86748216]]\n",
      "Train: 0.31, Val: 0.31, Test: 0.31\n",
      "loss 2.387 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.13149847 0.         0.86850153]]\n",
      "Train: 0.31, Val: 0.31, Test: 0.31\n",
      "loss 2.383 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.12844037 0.         0.87155963]]\n",
      "Train: 0.31, Val: 0.31, Test: 0.31\n",
      "loss 2.381 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.12538226 0.         0.87461774]]\n",
      "Train: 0.31, Val: 0.31, Test: 0.31\n",
      "loss 2.379 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.12334353 0.         0.87665647]]\n",
      "Train: 0.31, Val: 0.31, Test: 0.31\n",
      "loss 2.376 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.12130479 0.         0.87869521]]\n",
      "Train: 0.31, Val: 0.31, Test: 0.31\n",
      "loss 2.376 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.12028542 0.         0.87971458]]\n",
      "Train: 0.31, Val: 0.31, Test: 0.31\n",
      "loss 2.373 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.11926606 0.         0.88073394]]\n",
      "Train: 0.31, Val: 0.31, Test: 0.31\n",
      "loss 2.372 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.11620795 0.         0.88379205]]\n",
      "Train: 0.31, Val: 0.31, Test: 0.31\n",
      "loss 2.368 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.11416922 0.         0.88583078]]\n",
      "Train: 0.31, Val: 0.32, Test: 0.31\n",
      "loss 2.365 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.11314985 0.         0.88685015]]\n",
      "Train: 0.31, Val: 0.32, Test: 0.31\n",
      "loss 2.366 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.11314985 0.         0.88685015]]\n",
      "Train: 0.31, Val: 0.32, Test: 0.31\n",
      "loss 2.361 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.11111111 0.         0.88888889]]\n",
      "Train: 0.31, Val: 0.32, Test: 0.31\n",
      "loss 2.359 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.10805301 0.         0.89194699]]\n",
      "Train: 0.31, Val: 0.32, Test: 0.32\n",
      "loss 2.356 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.10601427 0.         0.89398573]]\n",
      "Train: 0.31, Val: 0.32, Test: 0.32\n",
      "loss 2.354 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.10397554 0.         0.89602446]]\n",
      "Train: 0.31, Val: 0.32, Test: 0.32\n",
      "loss 2.351 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.10295617 0.         0.89704383]]\n",
      "Train: 0.32, Val: 0.32, Test: 0.32\n",
      "loss 2.353 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.09989806 0.         0.90010194]]\n",
      "Train: 0.31, Val: 0.32, Test: 0.32\n",
      "loss 2.347 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.0988787  0.         0.9011213 ]]\n",
      "Train: 0.32, Val: 0.32, Test: 0.32\n",
      "loss 2.347 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.09378186 0.         0.90621814]]\n",
      "Train: 0.32, Val: 0.32, Test: 0.32\n",
      "loss 2.347 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.09072375 0.         0.90927625]]\n",
      "Train: 0.31, Val: 0.32, Test: 0.31\n",
      "loss 2.341 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.08766565 0.         0.91233435]]\n",
      "Train: 0.31, Val: 0.32, Test: 0.31\n",
      "loss 2.339 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.08664628 0.         0.91335372]]\n",
      "Train: 0.31, Val: 0.32, Test: 0.31\n",
      "loss 2.336 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.08154944 0.         0.91845056]]\n",
      "Train: 0.30, Val: 0.32, Test: 0.31\n",
      "loss 2.332 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.0764526  0.         0.9235474 ]]\n",
      "Train: 0.30, Val: 0.32, Test: 0.31\n",
      "loss 2.333 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.07543323 0.         0.92456677]]\n",
      "Train: 0.30, Val: 0.32, Test: 0.31\n",
      "loss 2.329 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.06829766 0.         0.93170234]]\n",
      "Train: 0.30, Val: 0.33, Test: 0.32\n",
      "loss 2.327 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.06320082 0.         0.93679918]]\n",
      "Train: 0.30, Val: 0.33, Test: 0.32\n",
      "loss 2.325 (26)\n",
      "[[0.08333333 0.         0.91666667]\n",
      " [0.         0.         1.        ]\n",
      " [0.06218145 0.         0.93781855]]\n",
      "Train: 0.30, Val: 0.33, Test: 0.32\n",
      "loss 2.320 (26)\n",
      "[[0.         0.         1.        ]\n",
      " [0.         0.         1.        ]\n",
      " [0.05912334 0.         0.94087666]]\n",
      "Train: 0.30, Val: 0.32, Test: 0.32\n",
      "loss 2.319 (26)\n",
      "[[0.        0.        1.       ]\n",
      " [0.        0.        1.       ]\n",
      " [0.0540265 0.        0.9459735]]\n",
      "Train: 0.30, Val: 0.32, Test: 0.32\n",
      "loss 2.319 (26)\n",
      "[[0.         0.         1.        ]\n",
      " [0.         0.         1.        ]\n",
      " [0.05300714 0.         0.94699286]]\n",
      "Train: 0.30, Val: 0.32, Test: 0.32\n",
      "loss 2.315 (26)\n",
      "[[0.         0.         1.        ]\n",
      " [0.         0.         1.        ]\n",
      " [0.04994903 0.         0.95005097]]\n",
      "Train: 0.30, Val: 0.32, Test: 0.32\n",
      "loss 2.316 (26)\n",
      "[[0.         0.         1.        ]\n",
      " [0.         0.         1.        ]\n",
      " [0.04587156 0.         0.95412844]]\n",
      "Train: 0.30, Val: 0.32, Test: 0.32\n",
      "loss 2.312 (26)\n",
      "[[0.         0.         1.        ]\n",
      " [0.         0.         1.        ]\n",
      " [0.04077472 0.         0.95922528]]\n",
      "Train: 0.31, Val: 0.32, Test: 0.32\n",
      "loss 2.307 (26)\n",
      "[[0.         0.         1.        ]\n",
      " [0.         0.         1.        ]\n",
      " [0.03669725 0.         0.96330275]]\n",
      "Train: 0.31, Val: 0.32, Test: 0.32\n",
      "loss 2.305 (26)\n",
      "[[0.         0.         1.        ]\n",
      " [0.         0.         1.        ]\n",
      " [0.03261978 0.         0.96738022]]\n",
      "Train: 0.31, Val: 0.32, Test: 0.32\n",
      "loss 2.303 (26)\n",
      "[[0.        0.        1.       ]\n",
      " [0.        0.        1.       ]\n",
      " [0.0285423 0.        0.9714577]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.32\n",
      "loss 2.299 (26)\n",
      "[[0.        0.        1.       ]\n",
      " [0.        0.        1.       ]\n",
      " [0.0254842 0.        0.9745158]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.32\n",
      "loss 2.297 (26)\n",
      "[[0.         0.         1.        ]\n",
      " [0.         0.         1.        ]\n",
      " [0.02140673 0.         0.97859327]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.293 (26)\n",
      "[[0.         0.         1.        ]\n",
      " [0.         0.         1.        ]\n",
      " [0.01427115 0.         0.98572885]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.292 (26)\n",
      "[[0.         0.         1.        ]\n",
      " [0.         0.         1.        ]\n",
      " [0.01325178 0.         0.98674822]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.291 (26)\n",
      "[[0.         0.         1.        ]\n",
      " [0.         0.         1.        ]\n",
      " [0.01121305 0.         0.98878695]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.286 (26)\n",
      "[[0.         0.         1.        ]\n",
      " [0.         0.         1.        ]\n",
      " [0.00815494 0.         0.99184506]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.286 (26)\n",
      "[[0.         0.         1.        ]\n",
      " [0.         0.         1.        ]\n",
      " [0.00203874 0.         0.99796126]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.284 (26)\n",
      "[[0.         0.         1.        ]\n",
      " [0.         0.         1.        ]\n",
      " [0.00101937 0.         0.99898063]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.282 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.278 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.277 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.276 (26)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.275 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.268 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.267 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.263 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.263 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.259 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.257 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.253 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.253 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.250 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.249 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.244 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.243 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.245 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.240 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.235 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.234 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.229 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.230 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.226 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.224 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.222 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.218 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.217 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.216 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.211 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.208 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.207 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.203 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.203 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.201 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.198 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.194 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.193 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.192 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.187 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.182 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.183 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.181 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.176 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.174 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.174 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.174 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.170 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.164 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.161 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.163 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.157 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.154 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.149 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.152 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.148 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.147 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.143 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.141 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.137 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.132 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.135 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.130 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.129 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.127 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.120 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.121 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.116 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.120 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.113 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.111 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.106 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.107 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.103 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.100 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.097 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.094 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.094 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.091 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.089 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.083 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.082 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.082 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.085 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.077 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.074 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.074 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.073 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.070 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.061 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.062 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.062 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.060 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.052 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.053 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.051 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.045 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.047 (26)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.044 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.042 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.037 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.032 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.037 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.031 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.031 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.025 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.024 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.019 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.016 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.017 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.017 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.014 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.006 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.004 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.002 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.000 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.000 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 2.001 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.996 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.995 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.989 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.988 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.984 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.983 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.979 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.978 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.976 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.970 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.970 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.966 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.962 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.964 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.964 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.955 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.955 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.955 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.949 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.950 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.945 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.948 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.941 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.939 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.936 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.934 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.932 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.930 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.930 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.926 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.926 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.918 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.918 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.918 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.909 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.913 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.913 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.905 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.901 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.904 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.902 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.895 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.899 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.892 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.890 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.883 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.886 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.886 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.886 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.879 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.881 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.876 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.872 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.868 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.869 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.871 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.862 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.865 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.865 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.860 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.849 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.854 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.846 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.850 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.846 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.845 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.842 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.838 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.841 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.835 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.835 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.836 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.833 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.833 (26)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.819 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.826 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.821 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.815 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.818 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.813 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.810 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.807 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.809 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.805 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.810 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.799 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.802 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.800 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.795 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.798 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.794 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.793 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.786 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.783 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.779 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.784 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.785 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.778 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.774 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.771 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.775 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.773 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.767 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.772 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.763 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.766 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.761 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.761 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.756 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.760 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.757 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.753 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.748 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.751 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.742 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.749 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.739 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.741 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.742 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.741 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.736 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.732 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.728 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.730 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.729 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.728 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.722 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.721 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.719 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.717 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.718 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.718 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.715 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.709 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.705 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.706 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.705 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.706 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.704 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.703 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.701 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.702 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.699 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.702 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.692 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.687 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.691 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.688 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.688 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.687 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.684 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.680 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.680 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.680 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.679 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.671 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.672 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.674 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.670 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.667 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.664 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.667 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.664 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.667 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.663 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.659 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.656 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 1.645 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.653 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.652 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.648 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.646 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.649 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.639 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.647 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.646 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.642 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.636 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.639 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.639 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.629 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.632 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.633 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.630 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.623 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.627 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.627 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.624 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.620 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.622 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.619 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.614 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.619 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.608 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.613 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.609 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.612 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.608 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.607 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.604 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.604 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.601 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.602 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.598 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.589 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.597 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.590 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.585 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.592 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.583 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.581 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.587 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.585 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.586 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.579 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.583 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.583 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.568 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.574 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.576 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.563 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.574 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.570 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.570 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.563 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.563 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.567 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.559 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.565 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.557 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.558 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.558 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.555 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.551 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.552 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.546 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.547 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.548 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.552 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.549 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.547 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.544 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.541 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.537 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.542 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.538 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.538 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.535 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.532 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.528 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.530 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.525 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.531 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.524 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.527 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.514 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.523 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.517 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.521 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.513 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.515 (26)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.513 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.515 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.512 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.514 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.513 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.512 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.507 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.502 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.494 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.500 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.503 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.496 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.496 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.491 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.493 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.485 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.493 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.495 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.493 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.484 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.485 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.486 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.487 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.483 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.479 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.476 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.477 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.479 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.479 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.481 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.474 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.477 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.463 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.470 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.471 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.467 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.459 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.462 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.458 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.457 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.461 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.460 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.456 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.454 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.456 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.447 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.449 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.445 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.450 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.450 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.445 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.448 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.444 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.442 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.439 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.435 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.438 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.439 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.437 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.438 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.430 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.433 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.432 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.428 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.425 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.429 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.417 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.414 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.417 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.414 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.411 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.423 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.422 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.420 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.417 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.420 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.407 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.410 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.406 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.410 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.403 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.406 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.396 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.407 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.398 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.401 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.399 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.391 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.396 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.389 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.392 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.396 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.391 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 1.389 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.391 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.388 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.384 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.381 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.381 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.382 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.384 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.380 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.378 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.379 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.379 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.362 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.373 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.371 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.376 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.368 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.371 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.369 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.368 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.372 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.358 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.364 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.357 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.358 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.354 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.358 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.351 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.355 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.357 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.348 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.350 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.351 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.338 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n",
      "loss 1.344 (26)\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Train: 0.31, Val: 0.33, Test: 0.33\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(model, device, train_loader, optimizer)\n",
    "    \n",
    "    train_acc, train_f1score, train_cm = test(model, device, train_loader)\n",
    "    val_acc, val_f1score, val_cm = test(model, device, val_loader)\n",
    "    test_acc, test_f1score, test_cm = test(model, device, test_loader)\n",
    "    print(val_cm)\n",
    "    print('Train: %.2f, Val: %.2f, Test: %.2f' %(train_f1score, val_f1score, test_f1score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, loader):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    gts = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            logits = model(data)\n",
    "            pred = torch.exp(logits).detach().cpu()\n",
    "            gt = target.cpu()\n",
    "            preds.append(pred)\n",
    "            gts.append(gt)\n",
    "    preds =  torch.cat(preds)\n",
    "    gts = torch.cat(gts)\n",
    "    return preds, gts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, target = predict(model, test_loader)\n",
    "pred1 = pred.argmax(dim=1, keepdim=True).squeeze()\n",
    "cm = confusion_matrix(target, pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def plot_confusion_matrix(cm, class_names=None, xlabel='Predicted label', ylabel='True label'):\n",
    "    \"\"\"\n",
    "    Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "\n",
    "    Args:\n",
    "      cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "      class_names (array, shape = [n]): String names of the integer classes\n",
    "    \"\"\"\n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    if class_names == None:\n",
    "        class_names = list(range(cm.shape[0]-1))\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=90)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "\n",
    "    # Use white text if squares are dark; otherwise black.\n",
    "    threshold = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        color = \"white\" if cm[i, j] > threshold else \"black\"\n",
    "        #plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel(xlabel)\n",
    "    return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(test_cm, class_names=keepers)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
