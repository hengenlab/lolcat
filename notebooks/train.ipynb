{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from src.data import Dataset\n",
    "from src.covariance import compute_cov, compute_edge_dist\n",
    "from src.network import MLP\n",
    "from src.dataloader import EdgeDistributionDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found processed pickle. Loading from '/Users/mehdiazabou/Documents/Nerds/cell_type/data/processed/dataset.pkl'.\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset('/Users/mehdiazabou/Documents/Nerds/cell_type/data', force_process=False)\n",
    "aggr_dict = {'e23Cux2': 'e23', 'i5Sst': 'i5Sst', 'i5Htr3a': 'i5Htr3a', 'e4Scnn1a': 'e4', 'e4Rorb': 'e4',\n",
    "             'e4other': 'e4', 'e4Nr5a1': 'e4', 'i6Htr3a': 'i6Htr3a', 'i6Sst': 'i6Sst', 'e6Ntsr1': 'e6',\n",
    "             'i23Pvalb': 'i23Pvalb', 'i23Htr3a': 'i23Htr3a', 'i1Htr3a': 'i1Htr3a', 'i4Sst': 'i4Sst', 'e5Rbp4': 'e5',\n",
    "             'e5noRbp4': 'e5', 'i23Sst': 'i23Sst', 'i4Htr3a': 'i4Htr3a', 'i6Pvalb': 'i6Pvalb', 'i5Pvalb': 'i5Pvalb',\n",
    "             'i4Pvalb': 'i4Pvalb'}\n",
    "dataset.aggregate_cell_classes(aggr_dict)\n",
    "# Split into train/val/test sets\n",
    "dataset.split_cell_train_val_test(test_size=0.2, val_size=0.2, seed=1234)\n",
    "dataset.split_trial_train_val_test(test_size=0.2, val_size=0.2, temp=True, seed=1234)\n",
    "\n",
    "# bining\n",
    "dataset.set_bining_parameters(bin_size=0.1) # in seconds, so this is 10ms"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# Create Pytorch datasets\n",
    "train_dataset = EdgeDistributionDataset(dataset, num_bins=10, dataset_size=100, mode='train', sampler='U20')\n",
    "val_dataset = EdgeDistributionDataset(dataset, num_bins=10, dataset_size=1, mode='val', sampler='U20', cell_random_seed=2, trial_id=70)\n",
    "test_dataset = EdgeDistributionDataset(dataset, num_bins=10, dataset_size=1, mode='test', sampler='U20', cell_random_seed=1, trial_id=90)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=10)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch, log_interval=None):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # concat batches\n",
    "        data = data.view((-1, data.size(2))).float()\n",
    "        target = target.view((-1,)).long()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if log_interval and batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, 100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "def test(model, device, loader, tag):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            # concat batches\n",
    "            data = data.view((-1, data.size(2))).float()\n",
    "            target = target.view((-1,)).long()\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            total += len(target)\n",
    "\n",
    "    print('{} set: Accuracy: {}/{} ({:.0f}%)'.format(tag,\n",
    "        correct, total,\n",
    "        100. * correct / total))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (model): Sequential(\n",
      "    (fc1): Linear(in_features=10, out_features=20, bias=True)\n",
      "    (relu1): ReLU()\n",
      "    (drop1): Dropout(p=0.2, inplace=False)\n",
      "    (fc2): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (relu2): ReLU()\n",
      "    (drop2): Dropout(p=0.2, inplace=False)\n",
      "    (fc3): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (relu3): ReLU()\n",
      "    (drop3): Dropout(p=0.2, inplace=False)\n",
      "    (out): Linear(in_features=20, out_features=17, bias=True)\n",
      "  )\n",
      ")\n",
      "Train Epoch: 1 [(0%)]\tLoss: 6.105129\n",
      "Train Epoch: 1 [(50%)]\tLoss: 2.898762\n",
      "\n",
      "Train set: Accuracy: 2001/34000 (6%)\n",
      "Val set: Accuracy: 20/340 (6%)\n",
      "Test set: Accuracy: 20/340 (6%)\n",
      "Train Epoch: 2 [(0%)]\tLoss: 2.835952\n",
      "Train Epoch: 2 [(50%)]\tLoss: 2.829023\n",
      "\n",
      "Train set: Accuracy: 1965/34000 (6%)\n",
      "Val set: Accuracy: 18/340 (5%)\n",
      "Test set: Accuracy: 18/340 (5%)\n",
      "Train Epoch: 3 [(0%)]\tLoss: 2.802915\n",
      "Train Epoch: 3 [(50%)]\tLoss: 2.775293\n",
      "\n",
      "Train set: Accuracy: 3678/34000 (11%)\n",
      "Val set: Accuracy: 39/340 (11%)\n",
      "Test set: Accuracy: 39/340 (11%)\n",
      "Train Epoch: 4 [(0%)]\tLoss: 2.750338\n",
      "Train Epoch: 4 [(50%)]\tLoss: 2.741044\n",
      "\n",
      "Train set: Accuracy: 3619/34000 (11%)\n",
      "Val set: Accuracy: 36/340 (11%)\n",
      "Test set: Accuracy: 37/340 (11%)\n",
      "Train Epoch: 5 [(0%)]\tLoss: 2.734608\n",
      "Train Epoch: 5 [(50%)]\tLoss: 2.718627\n",
      "\n",
      "Train set: Accuracy: 3609/34000 (11%)\n",
      "Val set: Accuracy: 36/340 (11%)\n",
      "Test set: Accuracy: 38/340 (11%)\n",
      "Train Epoch: 6 [(0%)]\tLoss: 2.718261\n",
      "Train Epoch: 6 [(50%)]\tLoss: 2.719258\n",
      "\n",
      "Train set: Accuracy: 3475/34000 (10%)\n",
      "Val set: Accuracy: 34/340 (10%)\n",
      "Test set: Accuracy: 36/340 (11%)\n",
      "Train Epoch: 7 [(0%)]\tLoss: 2.714408\n",
      "Train Epoch: 7 [(50%)]\tLoss: 2.715921\n",
      "\n",
      "Train set: Accuracy: 3761/34000 (11%)\n",
      "Val set: Accuracy: 44/340 (13%)\n",
      "Test set: Accuracy: 35/340 (10%)\n",
      "Train Epoch: 8 [(0%)]\tLoss: 2.706596\n",
      "Train Epoch: 8 [(50%)]\tLoss: 2.706697\n",
      "\n",
      "Train set: Accuracy: 3992/34000 (12%)\n",
      "Val set: Accuracy: 46/340 (14%)\n",
      "Test set: Accuracy: 47/340 (14%)\n",
      "Train Epoch: 9 [(0%)]\tLoss: 2.701667\n",
      "Train Epoch: 9 [(50%)]\tLoss: 2.702363\n",
      "\n",
      "Train set: Accuracy: 4138/34000 (12%)\n",
      "Val set: Accuracy: 49/340 (14%)\n",
      "Test set: Accuracy: 45/340 (13%)\n",
      "Train Epoch: 10 [(0%)]\tLoss: 2.704528\n",
      "Train Epoch: 10 [(50%)]\tLoss: 2.688272\n",
      "\n",
      "Train set: Accuracy: 4075/34000 (12%)\n",
      "Val set: Accuracy: 47/340 (14%)\n",
      "Test set: Accuracy: 44/340 (13%)\n",
      "Train Epoch: 11 [(0%)]\tLoss: 2.689718\n",
      "Train Epoch: 11 [(50%)]\tLoss: 2.690982\n",
      "\n",
      "Train set: Accuracy: 4097/34000 (12%)\n",
      "Val set: Accuracy: 51/340 (15%)\n",
      "Test set: Accuracy: 43/340 (13%)\n",
      "Train Epoch: 12 [(0%)]\tLoss: 2.691567\n",
      "Train Epoch: 12 [(50%)]\tLoss: 2.686659\n",
      "\n",
      "Train set: Accuracy: 4154/34000 (12%)\n",
      "Val set: Accuracy: 51/340 (15%)\n",
      "Test set: Accuracy: 47/340 (14%)\n",
      "Train Epoch: 13 [(0%)]\tLoss: 2.681602\n",
      "Train Epoch: 13 [(50%)]\tLoss: 2.681349\n",
      "\n",
      "Train set: Accuracy: 4257/34000 (13%)\n",
      "Val set: Accuracy: 53/340 (16%)\n",
      "Test set: Accuracy: 49/340 (14%)\n",
      "Train Epoch: 14 [(0%)]\tLoss: 2.668068\n",
      "Train Epoch: 14 [(50%)]\tLoss: 2.684699\n",
      "\n",
      "Train set: Accuracy: 4148/34000 (12%)\n",
      "Val set: Accuracy: 49/340 (14%)\n",
      "Test set: Accuracy: 44/340 (13%)\n",
      "Train Epoch: 15 [(0%)]\tLoss: 2.670129\n",
      "Train Epoch: 15 [(50%)]\tLoss: 2.680053\n",
      "\n",
      "Train set: Accuracy: 4235/34000 (12%)\n",
      "Val set: Accuracy: 53/340 (16%)\n",
      "Test set: Accuracy: 46/340 (14%)\n",
      "Train Epoch: 16 [(0%)]\tLoss: 2.678355\n",
      "Train Epoch: 16 [(50%)]\tLoss: 2.682399\n",
      "\n",
      "Train set: Accuracy: 4219/34000 (12%)\n",
      "Val set: Accuracy: 53/340 (16%)\n",
      "Test set: Accuracy: 47/340 (14%)\n",
      "Train Epoch: 17 [(0%)]\tLoss: 2.669993\n",
      "Train Epoch: 17 [(50%)]\tLoss: 2.678764\n",
      "\n",
      "Train set: Accuracy: 4434/34000 (13%)\n",
      "Val set: Accuracy: 54/340 (16%)\n",
      "Test set: Accuracy: 50/340 (15%)\n",
      "Train Epoch: 18 [(0%)]\tLoss: 2.669103\n",
      "Train Epoch: 18 [(50%)]\tLoss: 2.673842\n",
      "\n",
      "Train set: Accuracy: 4516/34000 (13%)\n",
      "Val set: Accuracy: 61/340 (18%)\n",
      "Test set: Accuracy: 55/340 (16%)\n",
      "Train Epoch: 19 [(0%)]\tLoss: 2.664032\n",
      "Train Epoch: 19 [(50%)]\tLoss: 2.681604\n",
      "\n",
      "Train set: Accuracy: 4504/34000 (13%)\n",
      "Val set: Accuracy: 55/340 (16%)\n",
      "Test set: Accuracy: 48/340 (14%)\n",
      "Train Epoch: 20 [(0%)]\tLoss: 2.661723\n",
      "Train Epoch: 20 [(50%)]\tLoss: 2.677323\n",
      "\n",
      "Train set: Accuracy: 4507/34000 (13%)\n",
      "Val set: Accuracy: 57/340 (17%)\n",
      "Test set: Accuracy: 51/340 (15%)\n",
      "Train Epoch: 21 [(0%)]\tLoss: 2.662759\n",
      "Train Epoch: 21 [(50%)]\tLoss: 2.672839\n",
      "\n",
      "Train set: Accuracy: 4596/34000 (14%)\n",
      "Val set: Accuracy: 58/340 (17%)\n",
      "Test set: Accuracy: 52/340 (15%)\n",
      "Train Epoch: 22 [(0%)]\tLoss: 2.660329\n",
      "Train Epoch: 22 [(50%)]\tLoss: 2.671922\n",
      "\n",
      "Train set: Accuracy: 4709/34000 (14%)\n",
      "Val set: Accuracy: 57/340 (17%)\n",
      "Test set: Accuracy: 54/340 (16%)\n",
      "Train Epoch: 23 [(0%)]\tLoss: 2.661558\n",
      "Train Epoch: 23 [(50%)]\tLoss: 2.666532\n",
      "\n",
      "Train set: Accuracy: 4724/34000 (14%)\n",
      "Val set: Accuracy: 58/340 (17%)\n",
      "Test set: Accuracy: 52/340 (15%)\n",
      "Train Epoch: 24 [(0%)]\tLoss: 2.652331\n",
      "Train Epoch: 24 [(50%)]\tLoss: 2.670161\n",
      "\n",
      "Train set: Accuracy: 4739/34000 (14%)\n",
      "Val set: Accuracy: 59/340 (17%)\n",
      "Test set: Accuracy: 52/340 (15%)\n",
      "Train Epoch: 25 [(0%)]\tLoss: 2.653585\n",
      "Train Epoch: 25 [(50%)]\tLoss: 2.668003\n",
      "\n",
      "Train set: Accuracy: 4654/34000 (14%)\n",
      "Val set: Accuracy: 58/340 (17%)\n",
      "Test set: Accuracy: 52/340 (15%)\n",
      "Train Epoch: 26 [(0%)]\tLoss: 2.653104\n",
      "Train Epoch: 26 [(50%)]\tLoss: 2.671129\n",
      "\n",
      "Train set: Accuracy: 4787/34000 (14%)\n",
      "Val set: Accuracy: 62/340 (18%)\n",
      "Test set: Accuracy: 53/340 (16%)\n",
      "Train Epoch: 27 [(0%)]\tLoss: 2.645303\n",
      "Train Epoch: 27 [(50%)]\tLoss: 2.658382\n",
      "\n",
      "Train set: Accuracy: 4782/34000 (14%)\n",
      "Val set: Accuracy: 60/340 (18%)\n",
      "Test set: Accuracy: 56/340 (16%)\n",
      "Train Epoch: 28 [(0%)]\tLoss: 2.644728\n",
      "Train Epoch: 28 [(50%)]\tLoss: 2.671123\n",
      "\n",
      "Train set: Accuracy: 4733/34000 (14%)\n",
      "Val set: Accuracy: 56/340 (16%)\n",
      "Test set: Accuracy: 56/340 (16%)\n",
      "Train Epoch: 29 [(0%)]\tLoss: 2.647142\n",
      "Train Epoch: 29 [(50%)]\tLoss: 2.664384\n",
      "\n",
      "Train set: Accuracy: 4744/34000 (14%)\n",
      "Val set: Accuracy: 62/340 (18%)\n",
      "Test set: Accuracy: 50/340 (15%)\n",
      "Train Epoch: 30 [(0%)]\tLoss: 2.662755\n",
      "Train Epoch: 30 [(50%)]\tLoss: 2.671153\n",
      "\n",
      "Train set: Accuracy: 4840/34000 (14%)\n",
      "Val set: Accuracy: 53/340 (16%)\n",
      "Test set: Accuracy: 52/340 (15%)\n",
      "Train Epoch: 31 [(0%)]\tLoss: 2.644164\n",
      "Train Epoch: 31 [(50%)]\tLoss: 2.661836\n",
      "\n",
      "Train set: Accuracy: 4852/34000 (14%)\n",
      "Val set: Accuracy: 60/340 (18%)\n",
      "Test set: Accuracy: 58/340 (17%)\n",
      "Train Epoch: 32 [(0%)]\tLoss: 2.638603\n",
      "Train Epoch: 32 [(50%)]\tLoss: 2.651218\n",
      "\n",
      "Train set: Accuracy: 4836/34000 (14%)\n",
      "Val set: Accuracy: 57/340 (17%)\n",
      "Test set: Accuracy: 57/340 (17%)\n",
      "Train Epoch: 33 [(0%)]\tLoss: 2.635688\n",
      "Train Epoch: 33 [(50%)]\tLoss: 2.660667\n",
      "\n",
      "Train set: Accuracy: 4901/34000 (14%)\n",
      "Val set: Accuracy: 57/340 (17%)\n",
      "Test set: Accuracy: 54/340 (16%)\n",
      "Train Epoch: 34 [(0%)]\tLoss: 2.633201\n",
      "Train Epoch: 34 [(50%)]\tLoss: 2.652071\n",
      "\n",
      "Train set: Accuracy: 4924/34000 (14%)\n",
      "Val set: Accuracy: 59/340 (17%)\n",
      "Test set: Accuracy: 55/340 (16%)\n",
      "Train Epoch: 35 [(0%)]\tLoss: 2.646438\n",
      "Train Epoch: 35 [(50%)]\tLoss: 2.657170\n",
      "\n",
      "Train set: Accuracy: 4907/34000 (14%)\n",
      "Val set: Accuracy: 55/340 (16%)\n",
      "Test set: Accuracy: 60/340 (18%)\n",
      "Train Epoch: 36 [(0%)]\tLoss: 2.638348\n",
      "Train Epoch: 36 [(50%)]\tLoss: 2.650998\n",
      "\n",
      "Train set: Accuracy: 4935/34000 (15%)\n",
      "Val set: Accuracy: 56/340 (16%)\n",
      "Test set: Accuracy: 53/340 (16%)\n",
      "Train Epoch: 37 [(0%)]\tLoss: 2.629251\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = MLP(input_dims=train_dataset.num_bins, n_hiddens=[20, 20, 20], n_class=17, dropout_p=0.2).to(device)\n",
    "print(model)\n",
    "\n",
    "lr = 1e-2\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "epochs=100\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(model, device, train_loader, optimizer, epoch, log_interval=5)\n",
    "    test(model, device, train_loader, '\\nTrain')\n",
    "    test(model, device, val_loader, 'Val')\n",
    "    test(model, device, test_loader, 'Test')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}