{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from src import Dataset, EdgeDistributionDataset\n",
    "from src.network import MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found processed pickle. Loading from '../data/processed/dataset.pkl'.\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset('../data', force_process=False)\n",
    "aggr_dict = {'e23Cux2': 'e23', 'i5Sst': 'i5Sst', 'i5Htr3a': 'i5Htr3a', 'e4Scnn1a': 'e4', 'e4Rorb': 'e4',\n",
    "             'e4other': 'e4', 'e4Nr5a1': 'e4', 'i6Htr3a': 'i6Htr3a', 'i6Sst': 'i6Sst', 'e6Ntsr1': 'e6',\n",
    "             'i23Pvalb': 'i23Pvalb', 'i23Htr3a': 'i23Htr3a', 'i1Htr3a': 'i1Htr3a', 'i4Sst': 'i4Sst', 'e5Rbp4': 'e5',\n",
    "             'e5noRbp4': 'e5', 'i23Sst': 'i23Sst', 'i4Htr3a': 'i4Htr3a', 'i6Pvalb': 'i6Pvalb', 'i5Pvalb': 'i5Pvalb',\n",
    "             'i4Pvalb': 'i4Pvalb'}\n",
    "dataset.aggregate_cell_classes(aggr_dict)\n",
    "dataset.num_trials_in_window = 2\n",
    "# Split into train/val/test sets\n",
    "dataset.split_cell_train_val_test(test_size=0.2, val_size=0.2, seed=1234)\n",
    "dataset.split_trial_train_val_test(test_size=0.2, val_size=0.2, temp=True, seed=1234)\n",
    "\n",
    "# bining\n",
    "dataset.set_bining_parameters(bin_size=0.1) # in seconds, so this is 10ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create Pytorch datasets\n",
    "train_dataset = EdgeDistributionDataset(dataset, edge_dist_num_bins=10, mode='train', sampler='U20')\n",
    "# fix population for validation set and test set (they will be different of course)\n",
    "val_dataset = EdgeDistributionDataset(dataset, edge_dist_num_bins=10, mode='val', sampler='U20', cell_random_seed=1)\n",
    "test_dataset = EdgeDistributionDataset(dataset, edge_dist_num_bins=10, mode='test', sampler='U20', cell_random_seed=1)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=5, collate_fn=train_dataset.collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, collate_fn=train_dataset.collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, collate_fn=train_dataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<src.pytorch_dataset.EdgeDistributionDataset object at 0x7f0552bd0100>\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch, log_interval=None):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if log_interval and batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, 100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "def test(model, device, loader, tag):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            total += len(target)\n",
    "\n",
    "    print('{} set: Accuracy: {}/{} ({:.0f}%)'.format(tag,\n",
    "        correct, total,\n",
    "        100. * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (model): Sequential(\n",
      "    (fc1): Linear(in_features=10, out_features=20, bias=True)\n",
      "    (relu1): ReLU()\n",
      "    (drop1): Dropout(p=0.2, inplace=False)\n",
      "    (fc2): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (relu2): ReLU()\n",
      "    (drop2): Dropout(p=0.2, inplace=False)\n",
      "    (fc3): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (relu3): ReLU()\n",
      "    (drop3): Dropout(p=0.2, inplace=False)\n",
      "    (out): Linear(in_features=20, out_features=17, bias=True)\n",
      "  )\n",
      ")\n",
      "Train Epoch: 1 [(0%)]\tLoss: 7.567725\n",
      "Train Epoch: 1 [(42%)]\tLoss: 5.741771\n",
      "Train Epoch: 1 [(83%)]\tLoss: 4.504419\n",
      "Train set: Accuracy: 735/20400 (4%)\n",
      "Val set: Accuracy: 269/6800 (4%)\n",
      "Test set: Accuracy: 242/6800 (4%)\n",
      "\n",
      "\n",
      "Train Epoch: 2 [(0%)]\tLoss: 4.178631\n",
      "Train Epoch: 2 [(42%)]\tLoss: 3.721102\n",
      "Train Epoch: 2 [(83%)]\tLoss: 3.427096\n",
      "Train set: Accuracy: 1251/20400 (6%)\n",
      "Val set: Accuracy: 438/6800 (6%)\n",
      "Test set: Accuracy: 427/6800 (6%)\n",
      "\n",
      "\n",
      "Train Epoch: 3 [(0%)]\tLoss: 3.294899\n",
      "Train Epoch: 3 [(42%)]\tLoss: 3.117541\n",
      "Train Epoch: 3 [(83%)]\tLoss: 3.060339\n",
      "Train set: Accuracy: 1303/20400 (6%)\n",
      "Val set: Accuracy: 455/6800 (7%)\n",
      "Test set: Accuracy: 500/6800 (7%)\n",
      "\n",
      "\n",
      "Train Epoch: 4 [(0%)]\tLoss: 3.076905\n",
      "Train Epoch: 4 [(42%)]\tLoss: 3.000680\n",
      "Train Epoch: 4 [(83%)]\tLoss: 2.939724\n",
      "Train set: Accuracy: 1309/20400 (6%)\n",
      "Val set: Accuracy: 455/6800 (7%)\n",
      "Test set: Accuracy: 416/6800 (6%)\n",
      "\n",
      "\n",
      "Train Epoch: 5 [(0%)]\tLoss: 2.963377\n",
      "Train Epoch: 5 [(42%)]\tLoss: 2.934710\n",
      "Train Epoch: 5 [(83%)]\tLoss: 2.934500\n",
      "Train set: Accuracy: 1162/20400 (6%)\n",
      "Val set: Accuracy: 402/6800 (6%)\n",
      "Test set: Accuracy: 364/6800 (5%)\n",
      "\n",
      "\n",
      "Train Epoch: 6 [(0%)]\tLoss: 2.911229\n",
      "Train Epoch: 6 [(42%)]\tLoss: 2.903340\n",
      "Train Epoch: 6 [(83%)]\tLoss: 2.895854\n",
      "Train set: Accuracy: 1179/20400 (6%)\n",
      "Val set: Accuracy: 398/6800 (6%)\n",
      "Test set: Accuracy: 391/6800 (6%)\n",
      "\n",
      "\n",
      "Train Epoch: 7 [(0%)]\tLoss: 2.885659\n",
      "Train Epoch: 7 [(42%)]\tLoss: 2.873821\n",
      "Train Epoch: 7 [(83%)]\tLoss: 2.870485\n",
      "Train set: Accuracy: 1200/20400 (6%)\n",
      "Val set: Accuracy: 400/6800 (6%)\n",
      "Test set: Accuracy: 400/6800 (6%)\n",
      "\n",
      "\n",
      "Train Epoch: 8 [(0%)]\tLoss: 2.854710\n",
      "Train Epoch: 8 [(42%)]\tLoss: 2.868503\n",
      "Train Epoch: 8 [(83%)]\tLoss: 2.850705\n",
      "Train set: Accuracy: 1200/20400 (6%)\n",
      "Val set: Accuracy: 400/6800 (6%)\n",
      "Test set: Accuracy: 400/6800 (6%)\n",
      "\n",
      "\n",
      "Train Epoch: 9 [(0%)]\tLoss: 2.850180\n",
      "Train Epoch: 9 [(42%)]\tLoss: 2.832907\n",
      "Train Epoch: 9 [(83%)]\tLoss: 2.840829\n",
      "Train set: Accuracy: 1869/20400 (9%)\n",
      "Val set: Accuracy: 664/6800 (10%)\n",
      "Test set: Accuracy: 625/6800 (9%)\n",
      "\n",
      "\n",
      "Train Epoch: 10 [(0%)]\tLoss: 2.849183\n",
      "Train Epoch: 10 [(42%)]\tLoss: 2.834153\n",
      "Train Epoch: 10 [(83%)]\tLoss: 2.845061\n",
      "Train set: Accuracy: 1843/20400 (9%)\n",
      "Val set: Accuracy: 664/6800 (10%)\n",
      "Test set: Accuracy: 626/6800 (9%)\n",
      "\n",
      "\n",
      "Train Epoch: 11 [(0%)]\tLoss: 2.833157\n",
      "Train Epoch: 11 [(42%)]\tLoss: 2.818389\n",
      "Train Epoch: 11 [(83%)]\tLoss: 2.819776\n",
      "Train set: Accuracy: 1817/20400 (9%)\n",
      "Val set: Accuracy: 654/6800 (10%)\n",
      "Test set: Accuracy: 610/6800 (9%)\n",
      "\n",
      "\n",
      "Train Epoch: 12 [(0%)]\tLoss: 2.804081\n",
      "Train Epoch: 12 [(42%)]\tLoss: 2.802526\n",
      "Train Epoch: 12 [(83%)]\tLoss: 2.801545\n",
      "Train set: Accuracy: 1755/20400 (9%)\n",
      "Val set: Accuracy: 634/6800 (9%)\n",
      "Test set: Accuracy: 603/6800 (9%)\n",
      "\n",
      "\n",
      "Train Epoch: 13 [(0%)]\tLoss: 2.805681\n",
      "Train Epoch: 13 [(42%)]\tLoss: 2.810395\n",
      "Train Epoch: 13 [(83%)]\tLoss: 2.793535\n",
      "Train set: Accuracy: 1761/20400 (9%)\n",
      "Val set: Accuracy: 651/6800 (10%)\n",
      "Test set: Accuracy: 609/6800 (9%)\n",
      "\n",
      "\n",
      "Train Epoch: 14 [(0%)]\tLoss: 2.796741\n",
      "Train Epoch: 14 [(42%)]\tLoss: 2.785903\n",
      "Train Epoch: 14 [(83%)]\tLoss: 2.783710\n",
      "Train set: Accuracy: 1788/20400 (9%)\n",
      "Val set: Accuracy: 647/6800 (10%)\n",
      "Test set: Accuracy: 606/6800 (9%)\n",
      "\n",
      "\n",
      "Train Epoch: 15 [(0%)]\tLoss: 2.776155\n",
      "Train Epoch: 15 [(42%)]\tLoss: 2.778882\n",
      "Train Epoch: 15 [(83%)]\tLoss: 2.782200\n",
      "Train set: Accuracy: 1782/20400 (9%)\n",
      "Val set: Accuracy: 661/6800 (10%)\n",
      "Test set: Accuracy: 614/6800 (9%)\n",
      "\n",
      "\n",
      "Train Epoch: 16 [(0%)]\tLoss: 2.788114\n",
      "Train Epoch: 16 [(42%)]\tLoss: 2.775361\n",
      "Train Epoch: 16 [(83%)]\tLoss: 2.770538\n",
      "Train set: Accuracy: 1835/20400 (9%)\n",
      "Val set: Accuracy: 661/6800 (10%)\n",
      "Test set: Accuracy: 616/6800 (9%)\n",
      "\n",
      "\n",
      "Train Epoch: 17 [(0%)]\tLoss: 2.771800\n",
      "Train Epoch: 17 [(42%)]\tLoss: 2.760443\n",
      "Train Epoch: 17 [(83%)]\tLoss: 2.758285\n",
      "Train set: Accuracy: 2335/20400 (11%)\n",
      "Val set: Accuracy: 836/6800 (12%)\n",
      "Test set: Accuracy: 786/6800 (12%)\n",
      "\n",
      "\n",
      "Train Epoch: 18 [(0%)]\tLoss: 2.763196\n",
      "Train Epoch: 18 [(42%)]\tLoss: 2.764900\n",
      "Train Epoch: 18 [(83%)]\tLoss: 2.769334\n",
      "Train set: Accuracy: 2310/20400 (11%)\n",
      "Val set: Accuracy: 832/6800 (12%)\n",
      "Test set: Accuracy: 783/6800 (12%)\n",
      "\n",
      "\n",
      "Train Epoch: 19 [(0%)]\tLoss: 2.762707\n",
      "Train Epoch: 19 [(42%)]\tLoss: 2.761502\n",
      "Train Epoch: 19 [(83%)]\tLoss: 2.760452\n",
      "Train set: Accuracy: 2225/20400 (11%)\n",
      "Val set: Accuracy: 784/6800 (12%)\n",
      "Test set: Accuracy: 774/6800 (11%)\n",
      "\n",
      "\n",
      "Train Epoch: 20 [(0%)]\tLoss: 2.745388\n",
      "Train Epoch: 20 [(42%)]\tLoss: 2.749317\n",
      "Train Epoch: 20 [(83%)]\tLoss: 2.740416\n",
      "Train set: Accuracy: 2275/20400 (11%)\n",
      "Val set: Accuracy: 818/6800 (12%)\n",
      "Test set: Accuracy: 753/6800 (11%)\n",
      "\n",
      "\n",
      "Train Epoch: 21 [(0%)]\tLoss: 2.756643\n",
      "Train Epoch: 21 [(42%)]\tLoss: 2.740184\n",
      "Train Epoch: 21 [(83%)]\tLoss: 2.744205\n",
      "Train set: Accuracy: 2334/20400 (11%)\n",
      "Val set: Accuracy: 825/6800 (12%)\n",
      "Test set: Accuracy: 772/6800 (11%)\n",
      "\n",
      "\n",
      "Train Epoch: 22 [(0%)]\tLoss: 2.729805\n",
      "Train Epoch: 22 [(42%)]\tLoss: 2.747702\n",
      "Train Epoch: 22 [(83%)]\tLoss: 2.750505\n",
      "Train set: Accuracy: 2333/20400 (11%)\n",
      "Val set: Accuracy: 825/6800 (12%)\n",
      "Test set: Accuracy: 773/6800 (11%)\n",
      "\n",
      "\n",
      "Train Epoch: 23 [(0%)]\tLoss: 2.730430\n",
      "Train Epoch: 23 [(42%)]\tLoss: 2.732275\n",
      "Train Epoch: 23 [(83%)]\tLoss: 2.738271\n",
      "Train set: Accuracy: 2447/20400 (12%)\n",
      "Val set: Accuracy: 861/6800 (13%)\n",
      "Test set: Accuracy: 808/6800 (12%)\n",
      "\n",
      "\n",
      "Train Epoch: 24 [(0%)]\tLoss: 2.732985\n",
      "Train Epoch: 24 [(42%)]\tLoss: 2.728585\n",
      "Train Epoch: 24 [(83%)]\tLoss: 2.733319\n",
      "Train set: Accuracy: 2482/20400 (12%)\n",
      "Val set: Accuracy: 857/6800 (13%)\n",
      "Test set: Accuracy: 809/6800 (12%)\n",
      "\n",
      "\n",
      "Train Epoch: 25 [(0%)]\tLoss: 2.743513\n",
      "Train Epoch: 25 [(42%)]\tLoss: 2.741333\n",
      "Train Epoch: 25 [(83%)]\tLoss: 2.736410\n",
      "Train set: Accuracy: 2506/20400 (12%)\n",
      "Val set: Accuracy: 861/6800 (13%)\n",
      "Test set: Accuracy: 810/6800 (12%)\n",
      "\n",
      "\n",
      "Train Epoch: 26 [(0%)]\tLoss: 2.736476\n",
      "Train Epoch: 26 [(42%)]\tLoss: 2.736989\n",
      "Train Epoch: 26 [(83%)]\tLoss: 2.715188\n",
      "Train set: Accuracy: 2536/20400 (12%)\n",
      "Val set: Accuracy: 880/6800 (13%)\n",
      "Test set: Accuracy: 833/6800 (12%)\n",
      "\n",
      "\n",
      "Train Epoch: 27 [(0%)]\tLoss: 2.729535\n",
      "Train Epoch: 27 [(42%)]\tLoss: 2.712311\n",
      "Train Epoch: 27 [(83%)]\tLoss: 2.724003\n",
      "Train set: Accuracy: 2531/20400 (12%)\n",
      "Val set: Accuracy: 874/6800 (13%)\n",
      "Test set: Accuracy: 821/6800 (12%)\n",
      "\n",
      "\n",
      "Train Epoch: 28 [(0%)]\tLoss: 2.728945\n",
      "Train Epoch: 28 [(42%)]\tLoss: 2.739359\n",
      "Train Epoch: 28 [(83%)]\tLoss: 2.710868\n",
      "Train set: Accuracy: 2497/20400 (12%)\n",
      "Val set: Accuracy: 871/6800 (13%)\n",
      "Test set: Accuracy: 818/6800 (12%)\n",
      "\n",
      "\n",
      "Train Epoch: 29 [(0%)]\tLoss: 2.725119\n",
      "Train Epoch: 29 [(42%)]\tLoss: 2.708674\n",
      "Train Epoch: 29 [(83%)]\tLoss: 2.730703\n",
      "Train set: Accuracy: 2486/20400 (12%)\n",
      "Val set: Accuracy: 862/6800 (13%)\n",
      "Test set: Accuracy: 811/6800 (12%)\n",
      "\n",
      "\n",
      "Train Epoch: 30 [(0%)]\tLoss: 2.735776\n",
      "Train Epoch: 30 [(42%)]\tLoss: 2.728372\n",
      "Train Epoch: 30 [(83%)]\tLoss: 2.709677\n",
      "Train set: Accuracy: 2582/20400 (13%)\n",
      "Val set: Accuracy: 888/6800 (13%)\n",
      "Test set: Accuracy: 846/6800 (12%)\n",
      "\n",
      "\n",
      "Train Epoch: 31 [(0%)]\tLoss: 2.711403\n",
      "Train Epoch: 31 [(42%)]\tLoss: 2.716440\n",
      "Train Epoch: 31 [(83%)]\tLoss: 2.733352\n",
      "Train set: Accuracy: 2540/20400 (12%)\n",
      "Val set: Accuracy: 879/6800 (13%)\n",
      "Test set: Accuracy: 832/6800 (12%)\n",
      "\n",
      "\n",
      "Train Epoch: 32 [(0%)]\tLoss: 2.720574\n",
      "Train Epoch: 32 [(42%)]\tLoss: 2.727211\n",
      "Train Epoch: 32 [(83%)]\tLoss: 2.704739\n",
      "Train set: Accuracy: 2619/20400 (13%)\n",
      "Val set: Accuracy: 888/6800 (13%)\n",
      "Test set: Accuracy: 845/6800 (12%)\n",
      "\n",
      "\n",
      "Train Epoch: 33 [(0%)]\tLoss: 2.714272\n",
      "Train Epoch: 33 [(42%)]\tLoss: 2.713035\n",
      "Train Epoch: 33 [(83%)]\tLoss: 2.709996\n",
      "Train set: Accuracy: 2644/20400 (13%)\n",
      "Val set: Accuracy: 904/6800 (13%)\n",
      "Test set: Accuracy: 852/6800 (13%)\n",
      "\n",
      "\n",
      "Train Epoch: 34 [(0%)]\tLoss: 2.704483\n",
      "Train Epoch: 34 [(42%)]\tLoss: 2.708215\n",
      "Train Epoch: 34 [(83%)]\tLoss: 2.701559\n",
      "Train set: Accuracy: 2557/20400 (13%)\n",
      "Val set: Accuracy: 878/6800 (13%)\n",
      "Test set: Accuracy: 826/6800 (12%)\n",
      "\n",
      "\n",
      "Train Epoch: 35 [(0%)]\tLoss: 2.717505\n",
      "Train Epoch: 35 [(42%)]\tLoss: 2.707167\n",
      "Train Epoch: 35 [(83%)]\tLoss: 2.704274\n",
      "Train set: Accuracy: 2595/20400 (13%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val set: Accuracy: 889/6800 (13%)\n",
      "Test set: Accuracy: 845/6800 (12%)\n",
      "\n",
      "\n",
      "Train Epoch: 36 [(0%)]\tLoss: 2.689241\n",
      "Train Epoch: 36 [(42%)]\tLoss: 2.710164\n",
      "Train Epoch: 36 [(83%)]\tLoss: 2.698013\n",
      "Train set: Accuracy: 2567/20400 (13%)\n",
      "Val set: Accuracy: 895/6800 (13%)\n",
      "Test set: Accuracy: 844/6800 (12%)\n",
      "\n",
      "\n",
      "Train Epoch: 37 [(0%)]\tLoss: 2.698731\n",
      "Train Epoch: 37 [(42%)]\tLoss: 2.693201\n",
      "Train Epoch: 37 [(83%)]\tLoss: 2.689985\n",
      "Train set: Accuracy: 2558/20400 (13%)\n",
      "Val set: Accuracy: 889/6800 (13%)\n",
      "Test set: Accuracy: 842/6800 (12%)\n",
      "\n",
      "\n",
      "Train Epoch: 38 [(0%)]\tLoss: 2.720267\n",
      "Train Epoch: 38 [(42%)]\tLoss: 2.685785\n",
      "Train Epoch: 38 [(83%)]\tLoss: 2.693865\n",
      "Train set: Accuracy: 2561/20400 (13%)\n",
      "Val set: Accuracy: 883/6800 (13%)\n",
      "Test set: Accuracy: 842/6800 (12%)\n",
      "\n",
      "\n",
      "Train Epoch: 39 [(0%)]\tLoss: 2.705918\n",
      "Train Epoch: 39 [(42%)]\tLoss: 2.698498\n",
      "Train Epoch: 39 [(83%)]\tLoss: 2.686997\n",
      "Train set: Accuracy: 2611/20400 (13%)\n",
      "Val set: Accuracy: 898/6800 (13%)\n",
      "Test set: Accuracy: 850/6800 (12%)\n",
      "\n",
      "\n",
      "Train Epoch: 40 [(0%)]\tLoss: 2.677710\n",
      "Train Epoch: 40 [(42%)]\tLoss: 2.689851\n",
      "Train Epoch: 40 [(83%)]\tLoss: 2.706791\n",
      "Train set: Accuracy: 2676/20400 (13%)\n",
      "Val set: Accuracy: 903/6800 (13%)\n",
      "Test set: Accuracy: 854/6800 (13%)\n",
      "\n",
      "\n",
      "Train Epoch: 41 [(0%)]\tLoss: 2.687886\n",
      "Train Epoch: 41 [(42%)]\tLoss: 2.681558\n",
      "Train Epoch: 41 [(83%)]\tLoss: 2.689723\n",
      "Train set: Accuracy: 2635/20400 (13%)\n",
      "Val set: Accuracy: 902/6800 (13%)\n",
      "Test set: Accuracy: 848/6800 (12%)\n",
      "\n",
      "\n",
      "Train Epoch: 42 [(0%)]\tLoss: 2.685615\n",
      "Train Epoch: 42 [(42%)]\tLoss: 2.678058\n",
      "Train Epoch: 42 [(83%)]\tLoss: 2.702117\n",
      "Train set: Accuracy: 2614/20400 (13%)\n",
      "Val set: Accuracy: 896/6800 (13%)\n",
      "Test set: Accuracy: 853/6800 (13%)\n",
      "\n",
      "\n",
      "Train Epoch: 43 [(0%)]\tLoss: 2.701035\n",
      "Train Epoch: 43 [(42%)]\tLoss: 2.694761\n",
      "Train Epoch: 43 [(83%)]\tLoss: 2.680809\n",
      "Train set: Accuracy: 2576/20400 (13%)\n",
      "Val set: Accuracy: 759/6800 (11%)\n",
      "Test set: Accuracy: 773/6800 (11%)\n",
      "\n",
      "\n",
      "Train Epoch: 44 [(0%)]\tLoss: 2.696106\n",
      "Train Epoch: 44 [(42%)]\tLoss: 2.695682\n",
      "Train Epoch: 44 [(83%)]\tLoss: 2.684385\n",
      "Train set: Accuracy: 2607/20400 (13%)\n",
      "Val set: Accuracy: 887/6800 (13%)\n",
      "Test set: Accuracy: 845/6800 (12%)\n",
      "\n",
      "\n",
      "Train Epoch: 45 [(0%)]\tLoss: 2.695355\n",
      "Train Epoch: 45 [(42%)]\tLoss: 2.687085\n",
      "Train Epoch: 45 [(83%)]\tLoss: 2.676193\n",
      "Train set: Accuracy: 2675/20400 (13%)\n",
      "Val set: Accuracy: 899/6800 (13%)\n",
      "Test set: Accuracy: 860/6800 (13%)\n",
      "\n",
      "\n",
      "Train Epoch: 46 [(0%)]\tLoss: 2.692853\n",
      "Train Epoch: 46 [(42%)]\tLoss: 2.698472\n",
      "Train Epoch: 46 [(83%)]\tLoss: 2.694869\n",
      "Train set: Accuracy: 2549/20400 (12%)\n",
      "Val set: Accuracy: 902/6800 (13%)\n",
      "Test set: Accuracy: 845/6800 (12%)\n",
      "\n",
      "\n",
      "Train Epoch: 47 [(0%)]\tLoss: 2.672127\n",
      "Train Epoch: 47 [(42%)]\tLoss: 2.688517\n",
      "Train Epoch: 47 [(83%)]\tLoss: 2.689247\n",
      "Train set: Accuracy: 2705/20400 (13%)\n",
      "Val set: Accuracy: 918/6800 (14%)\n",
      "Test set: Accuracy: 854/6800 (13%)\n",
      "\n",
      "\n",
      "Train Epoch: 48 [(0%)]\tLoss: 2.665158\n",
      "Train Epoch: 48 [(42%)]\tLoss: 2.675226\n",
      "Train Epoch: 48 [(83%)]\tLoss: 2.671805\n",
      "Train set: Accuracy: 2699/20400 (13%)\n",
      "Val set: Accuracy: 923/6800 (14%)\n",
      "Test set: Accuracy: 865/6800 (13%)\n",
      "\n",
      "\n",
      "Train Epoch: 49 [(0%)]\tLoss: 2.673901\n",
      "Train Epoch: 49 [(42%)]\tLoss: 2.688373\n",
      "Train Epoch: 49 [(83%)]\tLoss: 2.666188\n",
      "Train set: Accuracy: 2697/20400 (13%)\n",
      "Val set: Accuracy: 920/6800 (14%)\n",
      "Test set: Accuracy: 856/6800 (13%)\n",
      "\n",
      "\n",
      "Train Epoch: 50 [(0%)]\tLoss: 2.677385\n",
      "Train Epoch: 50 [(42%)]\tLoss: 2.680772\n",
      "Train Epoch: 50 [(83%)]\tLoss: 2.675715\n",
      "Train set: Accuracy: 2632/20400 (13%)\n",
      "Val set: Accuracy: 933/6800 (14%)\n",
      "Test set: Accuracy: 852/6800 (13%)\n",
      "\n",
      "\n",
      "Train Epoch: 51 [(0%)]\tLoss: 2.694167\n",
      "Train Epoch: 51 [(42%)]\tLoss: 2.659679\n",
      "Train Epoch: 51 [(83%)]\tLoss: 2.682630\n",
      "Train set: Accuracy: 2666/20400 (13%)\n",
      "Val set: Accuracy: 932/6800 (14%)\n",
      "Test set: Accuracy: 843/6800 (12%)\n",
      "\n",
      "\n",
      "Train Epoch: 52 [(0%)]\tLoss: 2.671588\n",
      "Train Epoch: 52 [(42%)]\tLoss: 2.679491\n",
      "Train Epoch: 52 [(83%)]\tLoss: 2.689705\n",
      "Train set: Accuracy: 2673/20400 (13%)\n",
      "Val set: Accuracy: 923/6800 (14%)\n",
      "Test set: Accuracy: 854/6800 (13%)\n",
      "\n",
      "\n",
      "Train Epoch: 53 [(0%)]\tLoss: 2.678450\n",
      "Train Epoch: 53 [(42%)]\tLoss: 2.688541\n",
      "Train Epoch: 53 [(83%)]\tLoss: 2.673686\n",
      "Train set: Accuracy: 2735/20400 (13%)\n",
      "Val set: Accuracy: 931/6800 (14%)\n",
      "Test set: Accuracy: 844/6800 (12%)\n",
      "\n",
      "\n",
      "Train Epoch: 54 [(0%)]\tLoss: 2.658442\n",
      "Train Epoch: 54 [(42%)]\tLoss: 2.677961\n",
      "Train Epoch: 54 [(83%)]\tLoss: 2.676490\n",
      "Train set: Accuracy: 2732/20400 (13%)\n",
      "Val set: Accuracy: 927/6800 (14%)\n",
      "Test set: Accuracy: 848/6800 (12%)\n",
      "\n",
      "\n",
      "Train Epoch: 55 [(0%)]\tLoss: 2.681917\n",
      "Train Epoch: 55 [(42%)]\tLoss: 2.690058\n",
      "Train Epoch: 55 [(83%)]\tLoss: 2.649904\n",
      "Train set: Accuracy: 2670/20400 (13%)\n",
      "Val set: Accuracy: 924/6800 (14%)\n",
      "Test set: Accuracy: 869/6800 (13%)\n",
      "\n",
      "\n",
      "Train Epoch: 56 [(0%)]\tLoss: 2.676230\n",
      "Train Epoch: 56 [(42%)]\tLoss: 2.682632\n",
      "Train Epoch: 56 [(83%)]\tLoss: 2.662750\n",
      "Train set: Accuracy: 2707/20400 (13%)\n",
      "Val set: Accuracy: 920/6800 (14%)\n",
      "Test set: Accuracy: 867/6800 (13%)\n",
      "\n",
      "\n",
      "Train Epoch: 57 [(0%)]\tLoss: 2.685440\n",
      "Train Epoch: 57 [(42%)]\tLoss: 2.680221\n",
      "Train Epoch: 57 [(83%)]\tLoss: 2.683319\n",
      "Train set: Accuracy: 2735/20400 (13%)\n",
      "Val set: Accuracy: 919/6800 (14%)\n",
      "Test set: Accuracy: 860/6800 (13%)\n",
      "\n",
      "\n",
      "Train Epoch: 58 [(0%)]\tLoss: 2.646557\n",
      "Train Epoch: 58 [(42%)]\tLoss: 2.681498\n",
      "Train Epoch: 58 [(83%)]\tLoss: 2.679713\n",
      "Train set: Accuracy: 2769/20400 (14%)\n",
      "Val set: Accuracy: 914/6800 (13%)\n",
      "Test set: Accuracy: 844/6800 (12%)\n",
      "\n",
      "\n",
      "Train Epoch: 59 [(0%)]\tLoss: 2.683699\n",
      "Train Epoch: 59 [(42%)]\tLoss: 2.664396\n",
      "Train Epoch: 59 [(83%)]\tLoss: 2.668890\n",
      "Train set: Accuracy: 2677/20400 (13%)\n",
      "Val set: Accuracy: 928/6800 (14%)\n",
      "Test set: Accuracy: 843/6800 (12%)\n",
      "\n",
      "\n",
      "Train Epoch: 60 [(0%)]\tLoss: 2.673337\n",
      "Train Epoch: 60 [(42%)]\tLoss: 2.676898\n",
      "Train Epoch: 60 [(83%)]\tLoss: 2.684386\n",
      "Train set: Accuracy: 2729/20400 (13%)\n",
      "Val set: Accuracy: 900/6800 (13%)\n",
      "Test set: Accuracy: 857/6800 (13%)\n",
      "\n",
      "\n",
      "Train Epoch: 61 [(0%)]\tLoss: 2.661663\n",
      "Train Epoch: 61 [(42%)]\tLoss: 2.657010\n",
      "Train Epoch: 61 [(83%)]\tLoss: 2.670044\n",
      "Train set: Accuracy: 2703/20400 (13%)\n",
      "Val set: Accuracy: 913/6800 (13%)\n",
      "Test set: Accuracy: 848/6800 (12%)\n",
      "\n",
      "\n",
      "Train Epoch: 62 [(0%)]\tLoss: 2.657805\n",
      "Train Epoch: 62 [(42%)]\tLoss: 2.682575\n",
      "Train Epoch: 62 [(83%)]\tLoss: 2.672030\n",
      "Train set: Accuracy: 2702/20400 (13%)\n",
      "Val set: Accuracy: 914/6800 (13%)\n",
      "Test set: Accuracy: 851/6800 (13%)\n",
      "\n",
      "\n",
      "Train Epoch: 63 [(0%)]\tLoss: 2.677052\n",
      "Train Epoch: 63 [(42%)]\tLoss: 2.665373\n",
      "Train Epoch: 63 [(83%)]\tLoss: 2.675420\n",
      "Train set: Accuracy: 2764/20400 (14%)\n",
      "Val set: Accuracy: 908/6800 (13%)\n",
      "Test set: Accuracy: 857/6800 (13%)\n",
      "\n",
      "\n",
      "Train Epoch: 64 [(0%)]\tLoss: 2.651112\n",
      "Train Epoch: 64 [(42%)]\tLoss: 2.674399\n",
      "Train Epoch: 64 [(83%)]\tLoss: 2.664164\n",
      "Train set: Accuracy: 2676/20400 (13%)\n",
      "Val set: Accuracy: 924/6800 (14%)\n",
      "Test set: Accuracy: 849/6800 (12%)\n",
      "\n",
      "\n",
      "Train Epoch: 65 [(0%)]\tLoss: 2.671118\n",
      "Train Epoch: 65 [(42%)]\tLoss: 2.651559\n",
      "Train Epoch: 65 [(83%)]\tLoss: 2.668226\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-87881e60098c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Val'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-4326ebe803ac>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, device, loader, tag)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aschneider61/cell_type/src/pytorch_dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mtrial_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaster_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mcov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_cov\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aschneider61/cell_type/src/data.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aschneider61/cell_type/src/data.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, mode, sampler, transform, cell_random_seed, trial_random_seed, trial_id)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;31m# todo probably want to use fine cell labels when doing this.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;31m#  If the number of cell types is reduced to 2 for example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         \u001b[0mselect_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcell_random_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;31m# select trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aschneider61/cell_type/src/data.py\u001b[0m in \u001b[0;36m_uniform_sampler\u001b[0;34m(self, mode, nbr_cells_per_class, random_seed)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0mselect_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell_type_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             select_mask.append(rng.choice(split_mask, nbr_cells_per_class, replace=False,\n\u001b[0m\u001b[1;32m    194\u001b[0m                                           p=split_lookup_table[i]/split_lookup_table[i].sum()))\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselect_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mgenerator.pyx\u001b[0m in \u001b[0;36mnumpy.random.generator.Generator.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mprod\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = MLP(input_dims=train_dataset.num_bins, n_hiddens=[20, 20, 20], n_class=17, dropout_p=0.2).to(device)\n",
    "print(model)\n",
    "\n",
    "lr = 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "epochs=100\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(model, device, train_loader, optimizer, epoch, log_interval=5)\n",
    "    test(model, device, train_loader, 'Train')\n",
    "    test(model, device, val_loader, 'Val')\n",
    "    test(model, device, test_loader, 'Test')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
