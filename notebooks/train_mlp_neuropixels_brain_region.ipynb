{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix,f1_score, accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../')\n",
    "\n",
    "from src import Dataset\n",
    "from src.network import MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] =\"7\" #specify gpu to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found processed pickle. Loading from '../data/processed/neuropixels_dataset-labels_brain_region.pkl'.\n"
     ]
    }
   ],
   "source": [
    "data_root = '../data/'\n",
    "dataset = Dataset(data_root, data_source='neuropixels', labels_col='brain_region') #specify data location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['grey', 'cortex', 'midbrain', 'hippocampus', 'thalamus', 'other']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.cell_type_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell classes identified by Louis as not being too quiet\n",
    "keepers = ['grey', 'cortex', 'midbrain', 'hippocampus', 'thalamus']\n",
    "dataset.drop_other_classes(classes_to_keep=keepers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "random_seed = 1\n",
    "test_size, val_size = 0.2, 0.2\n",
    "\n",
    "dataset.split_cell_train_val_test(test_size=test_size, val_size=val_size, seed=random_seed)\n",
    "X_train, y_train = dataset.get_set('train')\n",
    "X_val, y_val = dataset.get_set('val')\n",
    "X_test, y_test = dataset.get_set('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1., 2., 3., 4.]), array([18100, 43600,  5200, 18100, 18100]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute ISI distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hist(X, bins, a_min=-2.5, a_max=0.5):\n",
    "    X_isi = np.zeros((X.shape[0], bins))\n",
    "    bins = np.linspace(a_min, a_max, bins+1)\n",
    "    for i, x in enumerate(X):\n",
    "        # compute isi\n",
    "        x = np.diff(x)\n",
    "        # compute histogram\n",
    "        x = np.log10(x)\n",
    "        # x = np.clip(x, a_min=a_min, a_max=a_max)\n",
    "        X_isi[i] = np.histogram(x, bins)[0].astype(int)\n",
    "    return X_isi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bins = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = compute_hist(X_train, bins=num_bins)\n",
    "X_val = compute_hist(X_val, bins=num_bins)\n",
    "X_test = compute_hist(X_test, bins=num_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3093, 100, 128)\n"
     ]
    }
   ],
   "source": [
    "# reshape to (num_cells, num_trials, num_isi_bins)\n",
    "X_train = X_train.reshape(100, -1, num_bins).transpose(1,0,2)\n",
    "X_val = X_val.reshape(100, -1, num_bins).transpose(1,0,2)\n",
    "X_test = X_test.reshape(100, -1, num_bins).transpose(1,0,2)\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(100, -1).T[:, 0]\n",
    "y_val = y_val.reshape(100, -1).T[:, 0]\n",
    "y_test = y_test.reshape(100, -1).T[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "X_train, y_train = torch.FloatTensor(X_train).to(device), torch.LongTensor(y_train).to(device)\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "\n",
    "X_test, y_test = torch.FloatTensor(X_test).to(device), torch.LongTensor(y_test).to(device)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "X_val, y_val = torch.FloatTensor(X_val).to(device), torch.LongTensor(y_val).to(device)\n",
    "val_dataset = TensorDataset(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 1., 3., 2., 2.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "_, class_sample_count = torch.unique(y_train, return_counts=True)\n",
    "increase_factor = torch.floor(torch.pow(1.5, torch.floor(9 - torch.log(class_sample_count))))\n",
    "indices = []\n",
    "for cell_type, factor in enumerate(increase_factor.cpu()):\n",
    "    cell_indices = torch.where(y_train==cell_type)[0]\n",
    "    for _ in range(int(factor)):\n",
    "        indices.append(cell_indices)\n",
    "        \n",
    "print(increase_factor)\n",
    "\n",
    "indices = torch.cat(indices)\n",
    "sampler = SubsetRandomSampler(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=128, sampler=sampler, drop_last=True)\n",
    "train_eval_loader = DataLoader(train_dataset, batch_size=512, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=512, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class EncoderAggr(nn.Module):\n",
    "    def __init__(self, encoder, classifier, dropout_p=0.):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.classifier = classifier\n",
    "        \n",
    "        self.dropout_p = dropout_p\n",
    "        \n",
    "    def dropout(self, x):\n",
    "        if self.training and not self.dropout_p == 0:\n",
    "            dropout_mask = torch.empty((x.size(0), x.size(1), 1), dtype=torch.float32, device=x.device).uniform_(0, 1) > self.dropout_p\n",
    "            dropout_ratio = dropout_mask.sum(dim=1) / dropout_mask.size(1)\n",
    "\n",
    "            x = x * dropout_mask / dropout_ratio.view(x.size(0), 1, -1)\n",
    "        return x\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x = x.view(-1, num_bins)\n",
    "        emb = self.encoder(x)\n",
    "        \n",
    "        # aggregate feats\n",
    "        emb = emb.view(batch_size, 100, -1)\n",
    "        \n",
    "        # feature dropout\n",
    "        emb = self.dropout(emb)\n",
    "        \n",
    "        # compute global embedding\n",
    "        global_emb = torch.mean(emb, dim=1)\n",
    "        \n",
    "        out = self.classifier(global_emb)\n",
    "        \n",
    "        return nn.functional.log_softmax(out, dim=1)\n",
    "\n",
    "class MLPAggr(nn.Module):\n",
    "    def __init__(self, feat_dropout_p=0.2, net_dropout_p=0.2):\n",
    "        super().__init__()\n",
    "        encoder = nn.Sequential(nn.Linear(128, 64), nn.ReLU(), nn.Dropout(net_dropout_p), \n",
    "                                nn.Linear(64, 32), nn.ReLU(), nn.Dropout(net_dropout_p), \n",
    "                                nn.Linear(32, 32))\n",
    "        classifier = nn.Sequential(nn.Linear(32, 12), nn.ReLU(), nn.Linear(12, 6))\n",
    "        self.model = EncoderAggr(encoder, classifier, feat_dropout_p)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class topk_NLLLoss(nn.Module):\n",
    "    def __init__(self, top_k=0.7):\n",
    "        super().__init__()\n",
    "        self.loss = nn.NLLLoss(reduction='none')\n",
    "        self.top_k = top_k\n",
    "    \n",
    "    def forward(self, input, target):\n",
    "        loss = self.loss(input, target)\n",
    "\n",
    "        if self.top_k == 1:\n",
    "            return torch.mean(loss)\n",
    "        else:\n",
    "            valid_loss, idxs = torch.topk(loss, int(self.top_k * loss.size()[0]))    \n",
    "            return torch.mean(valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN THE MODEL\n",
    "model = MLPAggr(feat_dropout_p=0.7, net_dropout_p=0.2).to(device)\n",
    "\n",
    "lr = 1e-3\n",
    "weight_decay = 1e-5\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "criterion = topk_NLLLoss(0.8)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5000], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11866"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer):\n",
    "    model.train()\n",
    "    avg_loss = 0.\n",
    "    step = 0\n",
    "    for data, target in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_loss += loss.item()\n",
    "        step += 1\n",
    "        \n",
    "    print('loss %.3f (%d)' %(avg_loss/step, step))\n",
    "\n",
    "\n",
    "def test(model, device, loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    preds = []\n",
    "    corrects = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            pred_ = np.ndarray.flatten(pred.cpu().numpy())\n",
    "            targ_ = target.cpu().numpy()\n",
    "            preds.append(pred_)\n",
    "            corrects.append(targ_)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            total += len(target)\n",
    "    corrects = np.hstack(corrects)\n",
    "    preds = np.hstack(preds)\n",
    "    \n",
    "    acc = accuracy_score(corrects, preds)\n",
    "    f1score = f1_score(corrects, preds, average='macro')\n",
    "    cm = confusion_matrix(corrects, preds, normalize='true')\n",
    "    return acc, f1score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Hyperparameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 1.818 (39)\n",
      "Train: 0.18, Val: 0.19, Test: 0.20\n",
      "loss 1.748 (39)\n",
      "Train: 0.22, Val: 0.22, Test: 0.21\n",
      "loss 1.631 (39)\n",
      "Train: 0.23, Val: 0.21, Test: 0.23\n",
      "loss 1.589 (39)\n",
      "Train: 0.28, Val: 0.27, Test: 0.27\n",
      "loss 1.576 (39)\n",
      "Train: 0.29, Val: 0.28, Test: 0.28\n",
      "loss 1.569 (39)\n",
      "Train: 0.28, Val: 0.29, Test: 0.28\n",
      "loss 1.565 (39)\n",
      "Train: 0.23, Val: 0.22, Test: 0.24\n",
      "loss 1.563 (39)\n",
      "Train: 0.28, Val: 0.26, Test: 0.29\n",
      "loss 1.559 (39)\n",
      "Train: 0.31, Val: 0.28, Test: 0.27\n",
      "loss 1.558 (39)\n",
      "Train: 0.33, Val: 0.33, Test: 0.33\n",
      "loss 1.553 (39)\n",
      "Train: 0.28, Val: 0.30, Test: 0.30\n",
      "loss 1.548 (39)\n",
      "Train: 0.28, Val: 0.27, Test: 0.24\n",
      "loss 1.549 (39)\n",
      "Train: 0.35, Val: 0.33, Test: 0.30\n",
      "loss 1.544 (39)\n",
      "Train: 0.34, Val: 0.35, Test: 0.34\n",
      "loss 1.539 (39)\n",
      "Train: 0.37, Val: 0.35, Test: 0.35\n",
      "loss 1.536 (39)\n",
      "Train: 0.38, Val: 0.33, Test: 0.33\n",
      "loss 1.532 (39)\n",
      "Train: 0.38, Val: 0.38, Test: 0.36\n",
      "loss 1.527 (39)\n",
      "Train: 0.41, Val: 0.38, Test: 0.37\n",
      "loss 1.519 (39)\n",
      "Train: 0.38, Val: 0.35, Test: 0.33\n",
      "loss 1.519 (39)\n",
      "Train: 0.42, Val: 0.39, Test: 0.37\n",
      "loss 1.512 (39)\n",
      "Train: 0.39, Val: 0.38, Test: 0.37\n",
      "loss 1.501 (39)\n",
      "Train: 0.41, Val: 0.41, Test: 0.37\n",
      "loss 1.492 (39)\n",
      "Train: 0.39, Val: 0.38, Test: 0.37\n",
      "loss 1.483 (39)\n",
      "Train: 0.43, Val: 0.42, Test: 0.40\n",
      "loss 1.477 (39)\n",
      "Train: 0.39, Val: 0.42, Test: 0.39\n",
      "loss 1.470 (39)\n",
      "Train: 0.42, Val: 0.43, Test: 0.40\n",
      "loss 1.458 (39)\n",
      "Train: 0.44, Val: 0.42, Test: 0.41\n",
      "loss 1.453 (39)\n",
      "Train: 0.43, Val: 0.42, Test: 0.40\n",
      "loss 1.448 (39)\n",
      "Train: 0.44, Val: 0.44, Test: 0.42\n",
      "loss 1.441 (39)\n",
      "Train: 0.48, Val: 0.45, Test: 0.44\n",
      "loss 1.441 (39)\n",
      "Train: 0.45, Val: 0.43, Test: 0.41\n",
      "loss 1.434 (39)\n",
      "Train: 0.44, Val: 0.44, Test: 0.43\n",
      "loss 1.433 (39)\n",
      "Train: 0.46, Val: 0.43, Test: 0.42\n",
      "loss 1.419 (39)\n",
      "Train: 0.45, Val: 0.44, Test: 0.42\n",
      "loss 1.427 (39)\n",
      "Train: 0.47, Val: 0.44, Test: 0.44\n",
      "loss 1.426 (39)\n",
      "Train: 0.47, Val: 0.45, Test: 0.44\n",
      "loss 1.414 (39)\n",
      "Train: 0.46, Val: 0.43, Test: 0.42\n",
      "loss 1.411 (39)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-786ab267409b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain_cm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mval_cm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtest_cm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-649222ba7cb4>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, device, loader)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mcorrects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mtest_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# sum up batch loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(model, device, train_loader, optimizer)\n",
    "    train_cm, train_acc = test(model, device, train_loader)\n",
    "    val_cm, val_acc = test(model, device, val_loader)\n",
    "    test_cm, test_acc = test(model, device, test_loader)\n",
    "    \n",
    "    print('Train: %.2f, Val: %.2f, Test: %.2f' %(train_acc, val_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, loader):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    gts = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            logits = model(data)\n",
    "            pred = torch.exp(logits).detach().cpu()\n",
    "            gt = target.cpu()\n",
    "            preds.append(pred)\n",
    "            gts.append(gt)\n",
    "    preds =  torch.cat(preds)\n",
    "    gts = torch.cat(gts)\n",
    "    return preds, gts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, target = predict(model, test_loader)\n",
    "pred1 = pred.argmax(dim=1, keepdim=True).squeeze()\n",
    "test_cm = confusion_matrix(target, pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def plot_confusion_matrix(cm, class_names=None, xlabel='Predicted label', ylabel='True label'):\n",
    "    \"\"\"\n",
    "    Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "\n",
    "    Args:\n",
    "      cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "      class_names (array, shape = [n]): String names of the integer classes\n",
    "    \"\"\"\n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    if class_names == None:\n",
    "        class_names = list(range(cm.shape[0]-1))\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=90)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "\n",
    "    # Use white text if squares are dark; otherwise black.\n",
    "    threshold = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        color = \"white\" if cm[i, j] > threshold else \"black\"\n",
    "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel(xlabel)\n",
    "    return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(test_cm, class_names=keepers)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
